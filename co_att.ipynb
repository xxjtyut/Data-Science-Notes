{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xxjtyut/Data-Science-Notes/blob/master/co_att.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install spaCy==2.3.7\n",
        "! python -m spacy download en_vectors_web_lg\n",
        "import random\n",
        "import numpy as np\n",
        "from types import MethodType\n",
        "import os, json, torch, datetime, pickle, copy, shutil, time\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import torch.optim as Optim\n",
        "import re\n",
        "import en_vectors_web_lg\n",
        "import glob\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-07-08T23:54:49.038031Z",
          "iopub.execute_input": "2022-07-08T23:54:49.038976Z",
          "iopub.status.idle": "2022-07-08T23:55:11.047185Z",
          "shell.execute_reply.started": "2022-07-08T23:54:49.038928Z",
          "shell.execute_reply": "2022-07-08T23:55:11.046151Z"
        },
        "trusted": true,
        "id": "clNqxsluEyol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PATH:\n",
        "    def __init__(self):\n",
        "\n",
        "        # vqav2 dataset root path\n",
        "        self.DATASET_PATH = '../input/vqa-coatt/datasets/vqa/'\n",
        "\n",
        "        # bottom up features root path\n",
        "        self.FEATURE_PATH = '../input/vqa-coatt/datasets/coco_extract/'\n",
        "\n",
        "        self.init_path()\n",
        "\n",
        "\n",
        "    def init_path(self):\n",
        "\n",
        "        self.IMG_FEAT_PATH = {\n",
        "            'train': self.FEATURE_PATH + 'train2014/',\n",
        "            'val': self.FEATURE_PATH + 'val2014/',\n",
        "            'test': self.FEATURE_PATH + 'test2015/',\n",
        "        }\n",
        "\n",
        "        self.QUESTION_PATH = {\n",
        "            'train': self.DATASET_PATH + 'v2_OpenEnded_mscoco_train2014_questions.json',\n",
        "            'val': self.DATASET_PATH + 'v2_OpenEnded_mscoco_val2014_questions.json',\n",
        "            'test': self.DATASET_PATH + 'v2_OpenEnded_mscoco_test2015_questions.json',\n",
        "            'vg': self.DATASET_PATH + 'VG_questions.json',\n",
        "        }\n",
        "\n",
        "        self.ANSWER_PATH = {\n",
        "            'train': self.DATASET_PATH + 'v2_mscoco_train2014_annotations.json',\n",
        "            'val': self.DATASET_PATH + 'v2_mscoco_val2014_annotations.json',\n",
        "            'vg': self.DATASET_PATH + 'VG_annotations.json',\n",
        "        }\n",
        "\n",
        "        self.RESULT_PATH = './results_result_test/'\n",
        "        self.PRED_PATH = './results_pred/'\n",
        "        self.CACHE_PATH = './results_cache/'\n",
        "        self.LOG_PATH = './results_log/'\n",
        "        self.CKPTS_PATH = './ckpts/'\n",
        "\n",
        "        if 'results_result_test' not in os.listdir('./'):\n",
        "            os.mkdir('./results_result_test')\n",
        "\n",
        "        if 'results_pred' not in os.listdir('./'):\n",
        "            os.mkdir('./results_pred')\n",
        "\n",
        "        if 'results_cache' not in os.listdir('./'):\n",
        "            os.mkdir('./results_cache')\n",
        "\n",
        "        if 'results_log' not in os.listdir('./'):\n",
        "            os.mkdir('./results_log')\n",
        "\n",
        "        if 'ckpts' not in os.listdir('./'):\n",
        "            os.mkdir('./ckpts')\n",
        "\n",
        "\n",
        "    def check_path(self):\n",
        "        print('Checking dataset ...')\n",
        "\n",
        "        for mode in self.IMG_FEAT_PATH:\n",
        "            if not os.path.exists(self.IMG_FEAT_PATH[mode]):\n",
        "                print(self.IMG_FEAT_PATH[mode] + 'NOT EXIST')\n",
        "                exit(-1)\n",
        "\n",
        "        for mode in self.QUESTION_PATH:\n",
        "            if not os.path.exists(self.QUESTION_PATH[mode]):\n",
        "                print(self.QUESTION_PATH[mode] + 'NOT EXIST')\n",
        "                exit(-1)\n",
        "\n",
        "        for mode in self.ANSWER_PATH:\n",
        "            if not os.path.exists(self.ANSWER_PATH[mode]):\n",
        "                print(self.ANSWER_PATH[mode] + 'NOT EXIST')\n",
        "                exit(-1)\n",
        "\n",
        "        print('Finished')\n",
        "        print('')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-08T23:55:11.051402Z",
          "iopub.execute_input": "2022-07-08T23:55:11.051652Z",
          "iopub.status.idle": "2022-07-08T23:55:11.067148Z",
          "shell.execute_reply.started": "2022-07-08T23:55:11.05162Z",
          "shell.execute_reply": "2022-07-08T23:55:11.066253Z"
        },
        "trusted": true,
        "id": "3nE4Q5ouEyor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cfgs(PATH):\n",
        "    def __init__(self):\n",
        "        super(Cfgs, self).__init__()\n",
        "\n",
        "        # Set Devices\n",
        "        # If use multi-gpu training, set e.g.'0, 1, 2' instead\n",
        "        self.GPU = '0'\n",
        "\n",
        "        # Set RNG For CPU And GPUs\n",
        "        self.SEED = random.randint(0, 99999999)\n",
        "\n",
        "        # -------------------------\n",
        "        # ---- Version Control ----\n",
        "        # -------------------------\n",
        "\n",
        "        # Define a specific name to start new training\n",
        "        # self.VERSION = 'Anonymous_' + str(self.SEED)\n",
        "        self.VERSION = str(self.SEED)\n",
        "\n",
        "        # Resume training\n",
        "        self.RESUME = False\n",
        "\n",
        "        # Used in Resume training and testing\n",
        "        self.CKPT_VERSION = self.VERSION\n",
        "        self.CKPT_EPOCH = 0\n",
        "\n",
        "        # Absolutely checkpoint path, 'CKPT_VERSION' and 'CKPT_EPOCH' will be overridden\n",
        "        self.CKPT_PATH = None\n",
        "\n",
        "        # Print loss every step\n",
        "        self.VERBOSE = True\n",
        "\n",
        "\n",
        "        # ------------------------------\n",
        "        # ---- Data Provider Params ----\n",
        "        # ------------------------------\n",
        "\n",
        "        # {'train', 'val', 'test'}\n",
        "        self.RUN_MODE = 'train'\n",
        "\n",
        "        # Set True to evaluate offline\n",
        "        self.EVAL_EVERY_EPOCH = True\n",
        "\n",
        "        # Set True to save the prediction vector (Ensemble)\n",
        "        self.TEST_SAVE_PRED = False\n",
        "\n",
        "        # Pre-load the features into memory to increase the I/O speed\n",
        "        self.PRELOAD = False\n",
        "\n",
        "        # Define the 'train' 'val' 'test' data split\n",
        "        # (EVAL_EVERY_EPOCH triggered when set {'train': 'train'})\n",
        "        self.SPLIT = {\n",
        "            'train': '',\n",
        "            'val': 'val',\n",
        "            'test': 'test',\n",
        "        }\n",
        "\n",
        "        # A external method to set train split\n",
        "        self.TRAIN_SPLIT = 'train+val+vg'\n",
        "\n",
        "        # Set True to use pretrained word embedding\n",
        "        # (GloVe: spaCy https://spacy.io/)\n",
        "        self.USE_GLOVE = True\n",
        "\n",
        "        # Word embedding matrix size\n",
        "        # (token size x WORD_EMBED_SIZE)\n",
        "        self.WORD_EMBED_SIZE = 300\n",
        "\n",
        "        # Max length of question sentences\n",
        "        self.MAX_TOKEN = 14\n",
        "\n",
        "        # Filter the answer by occurrence\n",
        "        # self.ANS_FREQ = 8\n",
        "\n",
        "        # Max length of extracted faster-rcnn 2048D features\n",
        "        # (bottom-up and Top-down: https://github.com/peteanderson80/bottom-up-attention)\n",
        "        self.IMG_FEAT_PAD_SIZE = 100\n",
        "\n",
        "        # Faster-rcnn 2048D features\n",
        "        self.IMG_FEAT_SIZE = 2048\n",
        "\n",
        "        # Default training batch size: 64\n",
        "        self.BATCH_SIZE = 64\n",
        "\n",
        "        # Multi-thread I/O\n",
        "        self.NUM_WORKERS = 8\n",
        "\n",
        "        # Use pin memory\n",
        "        # (Warning: pin memory can accelerate GPU loading but may\n",
        "        # increase the CPU memory usage when NUM_WORKS is large)\n",
        "        self.PIN_MEM = True\n",
        "\n",
        "        # Large model can not training with batch size 64\n",
        "        # Gradient accumulate can split batch to reduce gpu memory usage\n",
        "        # (Warning: BATCH_SIZE should be divided by GRAD_ACCU_STEPS)\n",
        "        self.GRAD_ACCU_STEPS = 1\n",
        "\n",
        "        # Set 'external': use external shuffle method to implement training shuffle\n",
        "        # Set 'internal': use pytorch dataloader default shuffle method\n",
        "        self.SHUFFLE_MODE = 'external'\n",
        "\n",
        "\n",
        "        # ------------------------\n",
        "        # ---- Network Params ----\n",
        "        # ------------------------\n",
        "\n",
        "        # Model deeps\n",
        "        # (Encoder and Decoder will be same deeps)\n",
        "        self.LAYER = 6\n",
        "\n",
        "        # Model hidden size\n",
        "        # (512 as default, bigger will be a sharp increase of gpu memory usage)\n",
        "        self.HIDDEN_SIZE = 512\n",
        "\n",
        "        # Multi-head number in MCA layers\n",
        "        # (Warning: HIDDEN_SIZE should be divided by MULTI_HEAD)\n",
        "        self.MULTI_HEAD = 8\n",
        "\n",
        "        # Dropout rate for all dropout layers\n",
        "        # (dropout can prevent overfitting： [Dropout: a simple way to prevent neural networks from overfitting])\n",
        "        self.DROPOUT_R = 0.1\n",
        "\n",
        "        # MLP size in flatten layers\n",
        "        self.FLAT_MLP_SIZE = 512\n",
        "\n",
        "        # Flatten the last hidden to vector with {n} attention glimpses\n",
        "        self.FLAT_GLIMPSES = 1\n",
        "        self.FLAT_OUT_SIZE = 1024\n",
        "\n",
        "\n",
        "        # --------------------------\n",
        "        # ---- Optimizer Params ----\n",
        "        # --------------------------\n",
        "\n",
        "        # The base learning rate\n",
        "        self.LR_BASE = 0.0001\n",
        "\n",
        "        # Learning rate decay ratio\n",
        "        self.LR_DECAY_R = 0.2\n",
        "\n",
        "        # Learning rate decay at {x, y, z...} epoch\n",
        "        self.LR_DECAY_LIST = [10, 12]\n",
        "\n",
        "        # Max training epoch\n",
        "        self.MAX_EPOCH = 13\n",
        "\n",
        "        # Gradient clip\n",
        "        # (default: -1 means not using)\n",
        "        self.GRAD_NORM_CLIP = -1\n",
        "\n",
        "        # Adam optimizer betas and eps\n",
        "        self.OPT_BETAS = (0.9, 0.98)\n",
        "        self.OPT_EPS = 1e-9\n",
        "\n",
        "\n",
        "    def parse_to_dict(self, args):\n",
        "        args_dict = {}\n",
        "        for arg in dir(args):\n",
        "            if not arg.startswith('_') and not isinstance(getattr(args, arg), MethodType):\n",
        "                if getattr(args, arg) is not None:\n",
        "                    args_dict[arg] = getattr(args, arg)\n",
        "\n",
        "        return args_dict\n",
        "\n",
        "\n",
        "    def add_args(self, args_dict):\n",
        "        for arg in args_dict:\n",
        "            setattr(self, arg, args_dict[arg])\n",
        "\n",
        "\n",
        "    def proc(self):\n",
        "        assert self.RUN_MODE in ['train', 'val', 'test']\n",
        "\n",
        "        # ------------ Devices setup\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = self.GPU\n",
        "        self.N_GPU = len(self.GPU.split(','))\n",
        "        self.DEVICES = [_ for _ in range(self.N_GPU)]\n",
        "        torch.set_num_threads(2)\n",
        "\n",
        "\n",
        "        # ------------ Seed setup\n",
        "        # fix pytorch seed\n",
        "        torch.manual_seed(self.SEED)\n",
        "        if self.N_GPU < 2:\n",
        "            torch.cuda.manual_seed(self.SEED)\n",
        "        else:\n",
        "            torch.cuda.manual_seed_all(self.SEED)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "        # fix numpy seed\n",
        "        np.random.seed(self.SEED)\n",
        "\n",
        "        # fix random seed\n",
        "        random.seed(self.SEED)\n",
        "\n",
        "        if self.CKPT_PATH is not None:\n",
        "            print('Warning: you are now using CKPT_PATH args, '\n",
        "                  'CKPT_VERSION and CKPT_EPOCH will not work')\n",
        "            self.CKPT_VERSION = self.CKPT_PATH.split('/')[-1] + '_' + str(random.randint(0, 99999999))\n",
        "\n",
        "\n",
        "        # ------------ Split setup\n",
        "        self.SPLIT['train'] = self.TRAIN_SPLIT\n",
        "        if 'val' in self.SPLIT['train'].split('+') or self.RUN_MODE not in ['train']:\n",
        "            self.EVAL_EVERY_EPOCH = False\n",
        "\n",
        "        if self.RUN_MODE not in ['test']:\n",
        "            self.TEST_SAVE_PRED = False\n",
        "\n",
        "\n",
        "        # ------------ Gradient accumulate setup\n",
        "        assert self.BATCH_SIZE % self.GRAD_ACCU_STEPS == 0\n",
        "        self.SUB_BATCH_SIZE = int(self.BATCH_SIZE / self.GRAD_ACCU_STEPS)\n",
        "\n",
        "        # Use a small eval batch will reduce gpu memory usage\n",
        "        self.EVAL_BATCH_SIZE = int(self.SUB_BATCH_SIZE / 2)\n",
        "\n",
        "\n",
        "        # ------------ Networks setup\n",
        "        # FeedForwardNet size in every MCA layer\n",
        "        self.FF_SIZE = int(self.HIDDEN_SIZE * 4)\n",
        "\n",
        "        # A pipe line hidden size in attention compute\n",
        "        assert self.HIDDEN_SIZE % self.MULTI_HEAD == 0\n",
        "        self.HIDDEN_SIZE_HEAD = int(self.HIDDEN_SIZE / self.MULTI_HEAD)\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        for attr in dir(self):\n",
        "            if not attr.startswith('__') and not isinstance(getattr(self, attr), MethodType):\n",
        "                print('{ %-17s }->' % attr, getattr(self, attr))\n",
        "\n",
        "        return ''\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-08T23:55:11.06874Z",
          "iopub.execute_input": "2022-07-08T23:55:11.06924Z",
          "iopub.status.idle": "2022-07-08T23:55:11.099154Z",
          "shell.execute_reply.started": "2022-07-08T23:55:11.069196Z",
          "shell.execute_reply": "2022-07-08T23:55:11.098296Z"
        },
        "trusted": true,
        "id": "mnOqCOjiEyow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Execution:\n",
        "    def __init__(self, __C):\n",
        "        self.__C = __C\n",
        "\n",
        "        print('Loading training set ........')\n",
        "        self.dataset = DataSet(__C)\n",
        "\n",
        "        self.dataset_eval = None\n",
        "        if __C.EVAL_EVERY_EPOCH:\n",
        "            __C_eval = copy.deepcopy(__C)\n",
        "            setattr(__C_eval, 'RUN_MODE', 'val')\n",
        "\n",
        "            print('Loading validation set for per-epoch evaluation ........')\n",
        "            self.dataset_eval = DataSet(__C_eval)\n",
        "\n",
        "\n",
        "    def train(self, dataset, dataset_eval=None):\n",
        "\n",
        "        # Obtain needed information\n",
        "        data_size = dataset.data_size\n",
        "        token_size = dataset.token_size\n",
        "        ans_size = dataset.ans_size\n",
        "        pretrained_emb = dataset.pretrained_emb\n",
        "\n",
        "        # Define the MCAN model\n",
        "        net = Net(\n",
        "            self.__C,\n",
        "            pretrained_emb,\n",
        "            token_size,\n",
        "            ans_size\n",
        "        )\n",
        "        net.cuda()\n",
        "        net.train()\n",
        "\n",
        "        # Define the multi-gpu training if needed\n",
        "        if self.__C.N_GPU > 1:\n",
        "            net = nn.DataParallel(net, device_ids=self.__C.DEVICES)\n",
        "\n",
        "        # Define the binary cross entropy loss\n",
        "        # loss_fn = torch.nn.BCELoss(size_average=False).cuda()\n",
        "        loss_fn = torch.nn.BCELoss(reduction='sum').cuda()\n",
        "\n",
        "        # Load checkpoint if resume training\n",
        "        if self.__C.RESUME:\n",
        "            print(' ========== Resume training')\n",
        "\n",
        "            if self.__C.CKPT_PATH is not None:\n",
        "                print('Warning: you are now using CKPT_PATH args, '\n",
        "                      'CKPT_VERSION and CKPT_EPOCH will not work')\n",
        "\n",
        "                path = self.__C.CKPT_PATH\n",
        "            else:\n",
        "                path = self.__C.CKPTS_PATH + \\\n",
        "                       'ckpt_' + self.__C.CKPT_VERSION + \\\n",
        "                       '/epoch' + str(self.__C.CKPT_EPOCH) + '.pkl'\n",
        "\n",
        "            # Load the network parameters\n",
        "            print('Loading ckpt {}'.format(path))\n",
        "            ckpt = torch.load(path)\n",
        "            print('Finish!')\n",
        "            net.load_state_dict(ckpt['state_dict'])\n",
        "\n",
        "            # Load the optimizer paramters\n",
        "            optim = get_optim(self.__C, net, data_size, ckpt['lr_base'])\n",
        "            optim._step = int(data_size / self.__C.BATCH_SIZE * self.__C.CKPT_EPOCH)\n",
        "            optim.optimizer.load_state_dict(ckpt['optimizer'])\n",
        "\n",
        "            start_epoch = self.__C.CKPT_EPOCH\n",
        "\n",
        "        else:\n",
        "            if ('ckpt_' + self.__C.VERSION) in os.listdir(self.__C.CKPTS_PATH):\n",
        "                shutil.rmtree(self.__C.CKPTS_PATH + 'ckpt_' + self.__C.VERSION)\n",
        "\n",
        "            os.mkdir(self.__C.CKPTS_PATH + 'ckpt_' + self.__C.VERSION)\n",
        "\n",
        "            optim = get_optim(self.__C, net, data_size)\n",
        "            start_epoch = 0\n",
        "\n",
        "        loss_sum = 0\n",
        "        named_params = list(net.named_parameters())\n",
        "        grad_norm = np.zeros(len(named_params))\n",
        "\n",
        "        # Define multi-thread dataloader\n",
        "        if self.__C.SHUFFLE_MODE in ['external']:\n",
        "            dataloader = Data.DataLoader(\n",
        "                dataset,\n",
        "                batch_size=self.__C.BATCH_SIZE,\n",
        "                shuffle=False,\n",
        "                num_workers=self.__C.NUM_WORKERS,\n",
        "                pin_memory=self.__C.PIN_MEM,\n",
        "                drop_last=True\n",
        "            )\n",
        "        else:\n",
        "            dataloader = Data.DataLoader(\n",
        "                dataset,\n",
        "                batch_size=self.__C.BATCH_SIZE,\n",
        "                shuffle=True,\n",
        "                num_workers=self.__C.NUM_WORKERS,\n",
        "                pin_memory=self.__C.PIN_MEM,\n",
        "                drop_last=True\n",
        "            )\n",
        "\n",
        "        # Training script\n",
        "        for epoch in range(start_epoch, self.__C.MAX_EPOCH):\n",
        "\n",
        "            # Save log information\n",
        "            logfile = open(\n",
        "                self.__C.LOG_PATH +\n",
        "                'log_run_' + self.__C.VERSION + '.txt',\n",
        "                'a+'\n",
        "            )\n",
        "            logfile.write(\n",
        "                'nowTime: ' +\n",
        "                datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') +\n",
        "                '\\n'\n",
        "            )\n",
        "            logfile.close()\n",
        "\n",
        "            # Learning Rate Decay\n",
        "            if epoch in self.__C.LR_DECAY_LIST:\n",
        "                adjust_lr(optim, self.__C.LR_DECAY_R)\n",
        "\n",
        "            # Externally shuffle\n",
        "            if self.__C.SHUFFLE_MODE == 'external':\n",
        "                shuffle_list(dataset.ans_list)\n",
        "\n",
        "            time_start = time.time()\n",
        "            # Iteration\n",
        "            for step, (\n",
        "                    img_feat_iter,\n",
        "                    ques_ix_iter,\n",
        "                    ans_iter\n",
        "            ) in enumerate(dataloader):\n",
        "\n",
        "                optim.zero_grad()\n",
        "\n",
        "                img_feat_iter = img_feat_iter.cuda()\n",
        "                ques_ix_iter = ques_ix_iter.cuda()\n",
        "                ans_iter = ans_iter.cuda()\n",
        "\n",
        "                for accu_step in range(self.__C.GRAD_ACCU_STEPS):\n",
        "\n",
        "                    sub_img_feat_iter = \\\n",
        "                        img_feat_iter[accu_step * self.__C.SUB_BATCH_SIZE:\n",
        "                                      (accu_step + 1) * self.__C.SUB_BATCH_SIZE]\n",
        "                    sub_ques_ix_iter = \\\n",
        "                        ques_ix_iter[accu_step * self.__C.SUB_BATCH_SIZE:\n",
        "                                     (accu_step + 1) * self.__C.SUB_BATCH_SIZE]\n",
        "                    sub_ans_iter = \\\n",
        "                        ans_iter[accu_step * self.__C.SUB_BATCH_SIZE:\n",
        "                                 (accu_step + 1) * self.__C.SUB_BATCH_SIZE]\n",
        "\n",
        "\n",
        "                    pred = net(\n",
        "                        sub_img_feat_iter,\n",
        "                        sub_ques_ix_iter\n",
        "                    )\n",
        "\n",
        "                    loss = loss_fn(pred, sub_ans_iter)\n",
        "                    # only mean-reduction needs be divided by grad_accu_steps\n",
        "                    # removing this line wouldn't change our results because the speciality of Adam optimizer,\n",
        "                    # but would be necessary if you use SGD optimizer.\n",
        "                    # loss /= self.__C.GRAD_ACCU_STEPS\n",
        "                    loss.backward()\n",
        "                    loss_sum += loss.cpu().data.numpy() * self.__C.GRAD_ACCU_STEPS\n",
        "\n",
        "                    if self.__C.VERBOSE:\n",
        "                        if dataset_eval is not None:\n",
        "                            mode_str = self.__C.SPLIT['train'] + '->' + self.__C.SPLIT['val']\n",
        "                        else:\n",
        "                            mode_str = self.__C.SPLIT['train'] + '->' + self.__C.SPLIT['test']\n",
        "\n",
        "                        print(\"\\r[version %s][epoch %2d][step %4d/%4d][%s] loss: %.4f, lr: %.2e\" % (\n",
        "                            self.__C.VERSION,\n",
        "                            epoch + 1,\n",
        "                            step,\n",
        "                            int(data_size / self.__C.BATCH_SIZE),\n",
        "                            mode_str,\n",
        "                            loss.cpu().data.numpy() / self.__C.SUB_BATCH_SIZE,\n",
        "                            optim._rate\n",
        "                        ), end='          ')\n",
        "\n",
        "                # Gradient norm clipping\n",
        "                if self.__C.GRAD_NORM_CLIP > 0:\n",
        "                    nn.utils.clip_grad_norm_(\n",
        "                        net.parameters(),\n",
        "                        self.__C.GRAD_NORM_CLIP\n",
        "                    )\n",
        "\n",
        "                # Save the gradient information\n",
        "                for name in range(len(named_params)):\n",
        "                    norm_v = torch.norm(named_params[name][1].grad).cpu().data.numpy() \\\n",
        "                        if named_params[name][1].grad is not None else 0\n",
        "                    grad_norm[name] += norm_v * self.__C.GRAD_ACCU_STEPS\n",
        "                    # print('Param %-3s Name %-80s Grad_Norm %-20s'%\n",
        "                    #       (str(grad_wt),\n",
        "                    #        params[grad_wt][0],\n",
        "                    #        str(norm_v)))\n",
        "\n",
        "                optim.step()\n",
        "\n",
        "            time_end = time.time()\n",
        "            print('Finished in {}s'.format(int(time_end-time_start)))\n",
        "\n",
        "            # print('')\n",
        "            epoch_finish = epoch + 1\n",
        "\n",
        "            # Save checkpoint\n",
        "            state = {\n",
        "                'state_dict': net.state_dict(),\n",
        "                'optimizer': optim.optimizer.state_dict(),\n",
        "                'lr_base': optim.lr_base\n",
        "            }\n",
        "            torch.save(\n",
        "                state,\n",
        "                self.__C.CKPTS_PATH +\n",
        "                'ckpt_' + self.__C.VERSION +\n",
        "                '/epoch' + str(epoch_finish) +\n",
        "                '.pkl'\n",
        "            )\n",
        "\n",
        "            # Logging\n",
        "            logfile = open(\n",
        "                self.__C.LOG_PATH +\n",
        "                'log_run_' + self.__C.VERSION + '.txt',\n",
        "                'a+'\n",
        "            )\n",
        "            logfile.write(\n",
        "                'epoch = ' + str(epoch_finish) +\n",
        "                '  loss = ' + str(loss_sum / data_size) +\n",
        "                '\\n' +\n",
        "                'lr = ' + str(optim._rate) +\n",
        "                '\\n\\n'\n",
        "            )\n",
        "            logfile.close()\n",
        "\n",
        "            # Eval after every epoch\n",
        "            if dataset_eval is not None:\n",
        "                self.eval(\n",
        "                    dataset_eval,\n",
        "                    state_dict=net.state_dict(),\n",
        "                    valid=True\n",
        "                )\n",
        "\n",
        "            # if self.__C.VERBOSE:\n",
        "            #     logfile = open(\n",
        "            #         self.__C.LOG_PATH +\n",
        "            #         'log_run_' + self.__C.VERSION + '.txt',\n",
        "            #         'a+'\n",
        "            #     )\n",
        "            #     for name in range(len(named_params)):\n",
        "            #         logfile.write(\n",
        "            #             'Param %-3s Name %-80s Grad_Norm %-25s\\n' % (\n",
        "            #                 str(name),\n",
        "            #                 named_params[name][0],\n",
        "            #                 str(grad_norm[name] / data_size * self.__C.BATCH_SIZE)\n",
        "            #             )\n",
        "            #         )\n",
        "            #     logfile.write('\\n')\n",
        "            #     logfile.close()\n",
        "\n",
        "            loss_sum = 0\n",
        "            grad_norm = np.zeros(len(named_params))\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    def eval(self, dataset, state_dict=None, valid=False):\n",
        "\n",
        "        # Load parameters\n",
        "        if self.__C.CKPT_PATH is not None:\n",
        "            print('Warning: you are now using CKPT_PATH args, '\n",
        "                  'CKPT_VERSION and CKPT_EPOCH will not work')\n",
        "\n",
        "            path = self.__C.CKPT_PATH\n",
        "        else:\n",
        "            path = self.__C.CKPTS_PATH + \\\n",
        "                   'ckpt_' + self.__C.CKPT_VERSION + \\\n",
        "                   '/epoch' + str(self.__C.CKPT_EPOCH) + '.pkl'\n",
        "\n",
        "        val_ckpt_flag = False\n",
        "        if state_dict is None:\n",
        "            val_ckpt_flag = True\n",
        "            print('Loading ckpt {}'.format(path))\n",
        "            state_dict = torch.load(path)['state_dict']\n",
        "            print('Finish!')\n",
        "\n",
        "        # Store the prediction list\n",
        "        qid_list = [ques['question_id'] for ques in dataset.ques_list]\n",
        "        ans_ix_list = []\n",
        "        pred_list = []\n",
        "\n",
        "        data_size = dataset.data_size\n",
        "        token_size = dataset.token_size\n",
        "        ans_size = dataset.ans_size\n",
        "        pretrained_emb = dataset.pretrained_emb\n",
        "\n",
        "        net = Net(\n",
        "            self.__C,\n",
        "            pretrained_emb,\n",
        "            token_size,\n",
        "            ans_size\n",
        "        )\n",
        "        net.cuda()\n",
        "        net.eval()\n",
        "\n",
        "        if self.__C.N_GPU > 1:\n",
        "            net = nn.DataParallel(net, device_ids=self.__C.DEVICES)\n",
        "\n",
        "        net.load_state_dict(state_dict)\n",
        "\n",
        "        dataloader = Data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.__C.EVAL_BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            num_workers=self.__C.NUM_WORKERS,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        for step, (\n",
        "                img_feat_iter,\n",
        "                ques_ix_iter,\n",
        "                ans_iter\n",
        "        ) in enumerate(dataloader):\n",
        "            print(\"\\rEvaluation: [step %4d/%4d]\" % (\n",
        "                step,\n",
        "                int(data_size / self.__C.EVAL_BATCH_SIZE),\n",
        "            ), end='          ')\n",
        "\n",
        "            img_feat_iter = img_feat_iter.cuda()\n",
        "            ques_ix_iter = ques_ix_iter.cuda()\n",
        "\n",
        "            pred = net(\n",
        "                img_feat_iter,\n",
        "                ques_ix_iter\n",
        "            )\n",
        "            pred_np = pred.cpu().data.numpy()\n",
        "            pred_argmax = np.argmax(pred_np, axis=1)\n",
        "\n",
        "            # Save the answer index\n",
        "            if pred_argmax.shape[0] != self.__C.EVAL_BATCH_SIZE:\n",
        "                pred_argmax = np.pad(\n",
        "                    pred_argmax,\n",
        "                    (0, self.__C.EVAL_BATCH_SIZE - pred_argmax.shape[0]),\n",
        "                    mode='constant',\n",
        "                    constant_values=-1\n",
        "                )\n",
        "\n",
        "            ans_ix_list.append(pred_argmax)\n",
        "\n",
        "            # Save the whole prediction vector\n",
        "            if self.__C.TEST_SAVE_PRED:\n",
        "                if pred_np.shape[0] != self.__C.EVAL_BATCH_SIZE:\n",
        "                    pred_np = np.pad(\n",
        "                        pred_np,\n",
        "                        ((0, self.__C.EVAL_BATCH_SIZE - pred_np.shape[0]), (0, 0)),\n",
        "                        mode='constant',\n",
        "                        constant_values=-1\n",
        "                    )\n",
        "\n",
        "                pred_list.append(pred_np)\n",
        "\n",
        "        print('')\n",
        "        ans_ix_list = np.array(ans_ix_list).reshape(-1)\n",
        "\n",
        "        result = [{\n",
        "            'answer': dataset.ix_to_ans[str(ans_ix_list[qix])],  # ix_to_ans(load with json) keys are type of string\n",
        "            'question_id': int(qid_list[qix])\n",
        "        }for qix in range(qid_list.__len__())]\n",
        "\n",
        "        # Write the results to result file\n",
        "        if valid:\n",
        "            if val_ckpt_flag:\n",
        "                result_eval_file = \\\n",
        "                    self.__C.CACHE_PATH + \\\n",
        "                    'result_run_' + self.__C.CKPT_VERSION + \\\n",
        "                    '.json'\n",
        "            else:\n",
        "                result_eval_file = \\\n",
        "                    self.__C.CACHE_PATH + \\\n",
        "                    'result_run_' + self.__C.VERSION + \\\n",
        "                    '.json'\n",
        "\n",
        "        else:\n",
        "            if self.__C.CKPT_PATH is not None:\n",
        "                result_eval_file = \\\n",
        "                    self.__C.RESULT_PATH + \\\n",
        "                    'result_run_' + self.__C.CKPT_VERSION + \\\n",
        "                    '.json'\n",
        "            else:\n",
        "                result_eval_file = \\\n",
        "                    self.__C.RESULT_PATH + \\\n",
        "                    'result_run_' + self.__C.CKPT_VERSION + \\\n",
        "                    '_epoch' + str(self.__C.CKPT_EPOCH) + \\\n",
        "                    '.json'\n",
        "\n",
        "            print('Save the result to file: {}'.format(result_eval_file))\n",
        "\n",
        "        json.dump(result, open(result_eval_file, 'w'))\n",
        "\n",
        "        # Save the whole prediction vector\n",
        "        if self.__C.TEST_SAVE_PRED:\n",
        "\n",
        "            if self.__C.CKPT_PATH is not None:\n",
        "                ensemble_file = \\\n",
        "                    self.__C.PRED_PATH + \\\n",
        "                    'result_run_' + self.__C.CKPT_VERSION + \\\n",
        "                    '.json'\n",
        "            else:\n",
        "                ensemble_file = \\\n",
        "                    self.__C.PRED_PATH + \\\n",
        "                    'result_run_' + self.__C.CKPT_VERSION + \\\n",
        "                    '_epoch' + str(self.__C.CKPT_EPOCH) + \\\n",
        "                    '.json'\n",
        "\n",
        "            print('Save the prediction vector to file: {}'.format(ensemble_file))\n",
        "\n",
        "            pred_list = np.array(pred_list).reshape(-1, ans_size)\n",
        "            result_pred = [{\n",
        "                'pred': pred_list[qix],\n",
        "                'question_id': int(qid_list[qix])\n",
        "            }for qix in range(qid_list.__len__())]\n",
        "\n",
        "            pickle.dump(result_pred, open(ensemble_file, 'wb+'), protocol=-1)\n",
        "\n",
        "\n",
        "        # Run validation script\n",
        "        if valid:\n",
        "            # create vqa object and vqaRes object\n",
        "            ques_file_path = self.__C.QUESTION_PATH['val']\n",
        "            ans_file_path = self.__C.ANSWER_PATH['val']\n",
        "\n",
        "            vqa = VQA(ans_file_path, ques_file_path)\n",
        "            vqaRes = vqa.loadRes(result_eval_file, ques_file_path)\n",
        "\n",
        "            # create vqaEval object by taking vqa and vqaRes\n",
        "            vqaEval = VQAEval(vqa, vqaRes, n=2)  # n is precision of accuracy (number of places after decimal), default is 2\n",
        "\n",
        "            # evaluate results\n",
        "            \"\"\"\n",
        "            If you have a list of question ids on which you would like to evaluate your results, pass it as a list to below function\n",
        "            By default it uses all the question ids in annotation file\n",
        "            \"\"\"\n",
        "            vqaEval.evaluate()\n",
        "\n",
        "            # print accuracies\n",
        "            print(\"\\n\")\n",
        "            print(\"Overall Accuracy is: %.02f\\n\" % (vqaEval.accuracy['overall']))\n",
        "            # print(\"Per Question Type Accuracy is the following:\")\n",
        "            # for quesType in vqaEval.accuracy['perQuestionType']:\n",
        "            #     print(\"%s : %.02f\" % (quesType, vqaEval.accuracy['perQuestionType'][quesType]))\n",
        "            # print(\"\\n\")\n",
        "            print(\"Per Answer Type Accuracy is the following:\")\n",
        "            for ansType in vqaEval.accuracy['perAnswerType']:\n",
        "                print(\"%s : %.02f\" % (ansType, vqaEval.accuracy['perAnswerType'][ansType]))\n",
        "            print(\"\\n\")\n",
        "\n",
        "            if val_ckpt_flag:\n",
        "                print('Write to log file: {}'.format(\n",
        "                    self.__C.LOG_PATH +\n",
        "                    'log_run_' + self.__C.CKPT_VERSION + '.txt',\n",
        "                    'a+')\n",
        "                )\n",
        "\n",
        "                logfile = open(\n",
        "                    self.__C.LOG_PATH +\n",
        "                    'log_run_' + self.__C.CKPT_VERSION + '.txt',\n",
        "                    'a+'\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                print('Write to log file: {}'.format(\n",
        "                    self.__C.LOG_PATH +\n",
        "                    'log_run_' + self.__C.VERSION + '.txt',\n",
        "                    'a+')\n",
        "                )\n",
        "\n",
        "                logfile = open(\n",
        "                    self.__C.LOG_PATH +\n",
        "                    'log_run_' + self.__C.VERSION + '.txt',\n",
        "                    'a+'\n",
        "                )\n",
        "\n",
        "            logfile.write(\"Overall Accuracy is: %.02f\\n\" % (vqaEval.accuracy['overall']))\n",
        "            for ansType in vqaEval.accuracy['perAnswerType']:\n",
        "                logfile.write(\"%s : %.02f \" % (ansType, vqaEval.accuracy['perAnswerType'][ansType]))\n",
        "            logfile.write(\"\\n\\n\")\n",
        "            logfile.close()\n",
        "\n",
        "\n",
        "    def run(self, run_mode):\n",
        "        if run_mode == 'train':\n",
        "            self.empty_log(self.__C.VERSION)\n",
        "            self.train(self.dataset, self.dataset_eval)\n",
        "\n",
        "        elif run_mode == 'val':\n",
        "            self.eval(self.dataset, valid=True)\n",
        "\n",
        "        elif run_mode == 'test':\n",
        "            self.eval(self.dataset)\n",
        "\n",
        "        else:\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "    def empty_log(self, version):\n",
        "        print('Initializing log file ........')\n",
        "        if (os.path.exists(self.__C.LOG_PATH + 'log_run_' + version + '.txt')):\n",
        "            os.remove(self.__C.LOG_PATH + 'log_run_' + version + '.txt')\n",
        "        print('Finished!')\n",
        "        print('')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-08T23:55:11.10316Z",
          "iopub.execute_input": "2022-07-08T23:55:11.103415Z",
          "iopub.status.idle": "2022-07-08T23:55:11.173978Z",
          "shell.execute_reply.started": "2022-07-08T23:55:11.103388Z",
          "shell.execute_reply": "2022-07-08T23:55:11.173069Z"
        },
        "trusted": true,
        "id": "U5g0knHrEyo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# --------------------------------------------------------\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# ---- Multi-Head Attention ----\n",
        "# ------------------------------\n",
        "\n",
        "class MHAtt(nn.Module):\n",
        "    def __init__(self, __C):\n",
        "        super(MHAtt, self).__init__()\n",
        "        self.__C = __C\n",
        "\n",
        "        self.linear_v = nn.Linear(__C.HIDDEN_SIZE, __C.HIDDEN_SIZE)\n",
        "        self.linear_k = nn.Linear(__C.HIDDEN_SIZE, __C.HIDDEN_SIZE)\n",
        "        self.linear_q = nn.Linear(__C.HIDDEN_SIZE, __C.HIDDEN_SIZE)\n",
        "        self.linear_merge = nn.Linear(__C.HIDDEN_SIZE, __C.HIDDEN_SIZE)\n",
        "\n",
        "        self.dropout = nn.Dropout(__C.DROPOUT_R)\n",
        "\n",
        "    def forward(self, v, k, q, mask):\n",
        "        n_batches = q.size(0)\n",
        "\n",
        "        v = self.linear_v(v).view(\n",
        "            n_batches,\n",
        "            -1,\n",
        "            self.__C.MULTI_HEAD,\n",
        "            self.__C.HIDDEN_SIZE_HEAD\n",
        "        ).transpose(1, 2)\n",
        "\n",
        "        k = self.linear_k(k).view(\n",
        "            n_batches,\n",
        "            -1,\n",
        "            self.__C.MULTI_HEAD,\n",
        "            self.__C.HIDDEN_SIZE_HEAD\n",
        "        ).transpose(1, 2)\n",
        "\n",
        "        q = self.linear_q(q).view(\n",
        "            n_batches,\n",
        "            -1,\n",
        "            self.__C.MULTI_HEAD,\n",
        "            self.__C.HIDDEN_SIZE_HEAD\n",
        "        ).transpose(1, 2)\n",
        "\n",
        "        atted = self.att(v, k, q, mask)\n",
        "        atted = atted.transpose(1, 2).contiguous().view(\n",
        "            n_batches,\n",
        "            -1,\n",
        "            self.__C.HIDDEN_SIZE\n",
        "        )\n",
        "\n",
        "        atted = self.linear_merge(atted)\n",
        "\n",
        "        return atted\n",
        "\n",
        "    def att(self, value, key, query, mask):\n",
        "        d_k = query.size(-1)\n",
        "\n",
        "        scores = torch.matmul(\n",
        "            query, key.transpose(-2, -1)\n",
        "        ) / math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask, -1e9)\n",
        "\n",
        "        att_map = F.softmax(scores, dim=-1)\n",
        "        att_map = self.dropout(att_map)\n",
        "\n",
        "        return torch.matmul(att_map, value)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# ---- Feed Forward Nets ----\n",
        "# ---------------------------\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, __C):\n",
        "        super(FFN, self).__init__()\n",
        "\n",
        "        self.mlp = MLP(\n",
        "            in_size=__C.HIDDEN_SIZE,\n",
        "            mid_size=__C.FF_SIZE,\n",
        "            out_size=__C.HIDDEN_SIZE,\n",
        "            dropout_r=__C.DROPOUT_R,\n",
        "            use_relu=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# ---- Self Attention ----\n",
        "# ------------------------\n",
        "\n",
        "class SA(nn.Module):\n",
        "    def __init__(self, __C):\n",
        "        super(SA, self).__init__()\n",
        "\n",
        "        self.mhatt = MHAtt(__C)\n",
        "        self.ffn = FFN(__C)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(__C.DROPOUT_R)\n",
        "        self.norm1 = LayerNorm(__C.HIDDEN_SIZE)\n",
        "\n",
        "        self.dropout2 = nn.Dropout(__C.DROPOUT_R)\n",
        "        self.norm2 = LayerNorm(__C.HIDDEN_SIZE)\n",
        "\n",
        "    def forward(self, x, x_mask):\n",
        "        x = self.norm1(x + self.dropout1(\n",
        "            self.mhatt(x, x, x, x_mask)\n",
        "        ))\n",
        "\n",
        "        x = self.norm2(x + self.dropout2(\n",
        "            self.ffn(x)\n",
        "        ))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# ---- Self Guided Attention ----\n",
        "# -------------------------------\n",
        "\n",
        "class SGA(nn.Module):\n",
        "    def __init__(self, __C):\n",
        "        super(SGA, self).__init__()\n",
        "\n",
        "        self.mhatt1 = MHAtt(__C)\n",
        "        self.mhatt2 = MHAtt(__C)\n",
        "        self.ffn = FFN(__C)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(__C.DROPOUT_R)\n",
        "        self.norm1 = LayerNorm(__C.HIDDEN_SIZE)\n",
        "\n",
        "        self.dropout2 = nn.Dropout(__C.DROPOUT_R)\n",
        "        self.norm2 = LayerNorm(__C.HIDDEN_SIZE)\n",
        "\n",
        "        self.dropout3 = nn.Dropout(__C.DROPOUT_R)\n",
        "        self.norm3 = LayerNorm(__C.HIDDEN_SIZE)\n",
        "\n",
        "    def forward(self, x, y, x_mask, y_mask):\n",
        "        x = self.norm1(x + self.dropout1(\n",
        "            self.mhatt1(x, x, x, x_mask)\n",
        "        ))\n",
        "\n",
        "        x = self.norm2(x + self.dropout2(\n",
        "            self.mhatt2(y, y, x, y_mask)\n",
        "        ))\n",
        "\n",
        "        x = self.norm3(x + self.dropout3(\n",
        "            self.ffn(x)\n",
        "        ))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# ------------------------------------------------\n",
        "# ---- MAC Layers Cascaded by Encoder-Decoder ----\n",
        "# ------------------------------------------------\n",
        "\n",
        "class MCA_ED(nn.Module):\n",
        "    def __init__(self, __C):\n",
        "        super(MCA_ED, self).__init__()\n",
        "\n",
        "        self.enc_list = nn.ModuleList([SA(__C) for _ in range(__C.LAYER)])\n",
        "        self.dec_list = nn.ModuleList([SGA(__C) for _ in range(__C.LAYER)])\n",
        "\n",
        "    def forward(self, x, y, x_mask, y_mask):\n",
        "        # Get hidden vector\n",
        "        for enc in self.enc_list:\n",
        "            x = enc(x, x_mask)\n",
        "\n",
        "        for dec in self.dec_list:\n",
        "            y = dec(y, x, y_mask, x_mask)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# --------------------------------------------------------\n",
        "\n",
        "# ------------------------------\n",
        "# ---- Flatten the sequence ----\n",
        "# ------------------------------\n",
        "\n",
        "class AttFlat(nn.Module):\n",
        "    def __init__(self, __C):\n",
        "        super(AttFlat, self).__init__()\n",
        "        self.__C = __C\n",
        "\n",
        "        self.mlp = MLP(\n",
        "            in_size=__C.HIDDEN_SIZE,\n",
        "            mid_size=__C.FLAT_MLP_SIZE,\n",
        "            out_size=__C.FLAT_GLIMPSES,\n",
        "            dropout_r=__C.DROPOUT_R,\n",
        "            use_relu=True\n",
        "        )\n",
        "\n",
        "        self.linear_merge = nn.Linear(\n",
        "            __C.HIDDEN_SIZE * __C.FLAT_GLIMPSES,\n",
        "            __C.FLAT_OUT_SIZE\n",
        "        )\n",
        "\n",
        "    def forward(self, x, x_mask):\n",
        "        att = self.mlp(x)\n",
        "        att = att.masked_fill(\n",
        "            x_mask.squeeze(1).squeeze(1).unsqueeze(2),\n",
        "            -1e9\n",
        "        )\n",
        "        att = F.softmax(att, dim=1)\n",
        "\n",
        "        att_list = []\n",
        "        for i in range(self.__C.FLAT_GLIMPSES):\n",
        "            att_list.append(\n",
        "                torch.sum(att[:, :, i: i + 1] * x, dim=1)\n",
        "            )\n",
        "\n",
        "        x_atted = torch.cat(att_list, dim=1)\n",
        "        x_atted = self.linear_merge(x_atted)\n",
        "\n",
        "        return x_atted\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# ---- Main MCAN Model ----\n",
        "# -------------------------\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, __C, pretrained_emb, token_size, answer_size):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=token_size,\n",
        "            embedding_dim=__C.WORD_EMBED_SIZE\n",
        "        )\n",
        "\n",
        "        # Loading the GloVe embedding weights\n",
        "        if __C.USE_GLOVE:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_emb))\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=__C.WORD_EMBED_SIZE,\n",
        "            hidden_size=__C.HIDDEN_SIZE,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.img_feat_linear = nn.Linear(\n",
        "            __C.IMG_FEAT_SIZE,\n",
        "            __C.HIDDEN_SIZE\n",
        "        )\n",
        "\n",
        "        self.backbone = MCA_ED(__C)\n",
        "\n",
        "        self.attflat_img = AttFlat(__C)\n",
        "        self.attflat_lang = AttFlat(__C)\n",
        "\n",
        "        self.proj_norm = LayerNorm(__C.FLAT_OUT_SIZE)\n",
        "        self.proj = nn.Linear(__C.FLAT_OUT_SIZE, answer_size)\n",
        "\n",
        "\n",
        "    def forward(self, img_feat, ques_ix):\n",
        "\n",
        "        # Make mask\n",
        "        lang_feat_mask = self.make_mask(ques_ix.unsqueeze(2))\n",
        "        img_feat_mask = self.make_mask(img_feat)\n",
        "\n",
        "        # Pre-process Language Feature\n",
        "        lang_feat = self.embedding(ques_ix)\n",
        "        lang_feat, _ = self.lstm(lang_feat)\n",
        "\n",
        "        # Pre-process Image Feature\n",
        "        img_feat = self.img_feat_linear(img_feat)\n",
        "\n",
        "        # Backbone Framework\n",
        "        lang_feat, img_feat = self.backbone(\n",
        "            lang_feat,\n",
        "            img_feat,\n",
        "            lang_feat_mask,\n",
        "            img_feat_mask\n",
        "        )\n",
        "\n",
        "        lang_feat = self.attflat_lang(\n",
        "            lang_feat,\n",
        "            lang_feat_mask\n",
        "        )\n",
        "\n",
        "        img_feat = self.attflat_img(\n",
        "            img_feat,\n",
        "            img_feat_mask\n",
        "        )\n",
        "\n",
        "        proj_feat = lang_feat + img_feat\n",
        "        proj_feat = self.proj_norm(proj_feat)\n",
        "        proj_feat = torch.sigmoid(self.proj(proj_feat))\n",
        "\n",
        "        return proj_feat\n",
        "\n",
        "\n",
        "    # Masking\n",
        "    def make_mask(self, feature):\n",
        "        return (torch.sum(\n",
        "            torch.abs(feature),\n",
        "            dim=-1\n",
        "        ) == 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# --------------------------------------------------------\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n",
        "        super(FC, self).__init__()\n",
        "        self.dropout_r = dropout_r\n",
        "        self.use_relu = use_relu\n",
        "\n",
        "        self.linear = nn.Linear(in_size, out_size)\n",
        "\n",
        "        if use_relu:\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if dropout_r > 0:\n",
        "            self.dropout = nn.Dropout(dropout_r)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "\n",
        "        if self.use_relu:\n",
        "            x = self.relu(x)\n",
        "\n",
        "        if self.dropout_r > 0:\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_size, mid_size, out_size, dropout_r=0., use_relu=True):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.fc = FC(in_size, mid_size, dropout_r=dropout_r, use_relu=use_relu)\n",
        "        self.linear = nn.Linear(mid_size, out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(self.fc(x))\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, size, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "        self.a_2 = nn.Parameter(torch.ones(size))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# --------------------------------------------------------\n",
        "\n",
        "\n",
        "class WarmupOptimizer(object):\n",
        "    def __init__(self, lr_base, optimizer, data_size, batch_size):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.lr_base = lr_base\n",
        "        self._rate = 0\n",
        "        self.data_size = data_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "\n",
        "    def step(self):\n",
        "        self._step += 1\n",
        "\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    def rate(self, step=None):\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "\n",
        "        if step <= int(self.data_size / self.batch_size * 1):\n",
        "            r = self.lr_base * 1/4.\n",
        "        elif step <= int(self.data_size / self.batch_size * 2):\n",
        "            r = self.lr_base * 2/4.\n",
        "        elif step <= int(self.data_size / self.batch_size * 3):\n",
        "            r = self.lr_base * 3/4.\n",
        "        else:\n",
        "            r = self.lr_base\n",
        "\n",
        "        return r\n",
        "\n",
        "\n",
        "def get_optim(__C, model, data_size, lr_base=None):\n",
        "    if lr_base is None:\n",
        "        lr_base = __C.LR_BASE\n",
        "\n",
        "    return WarmupOptimizer(\n",
        "        lr_base,\n",
        "        Optim.Adam(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=0,\n",
        "            betas=__C.OPT_BETAS,\n",
        "            eps=__C.OPT_EPS\n",
        "        ),\n",
        "        data_size,\n",
        "        __C.BATCH_SIZE\n",
        "    )\n",
        "\n",
        "\n",
        "def adjust_lr(optim, decay_r):\n",
        "    optim.lr_base *= decay_r\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-08T23:55:11.175711Z",
          "iopub.execute_input": "2022-07-08T23:55:11.175983Z",
          "iopub.status.idle": "2022-07-08T23:55:11.239657Z",
          "shell.execute_reply.started": "2022-07-08T23:55:11.175945Z",
          "shell.execute_reply": "2022-07-08T23:55:11.23894Z"
        },
        "trusted": true,
        "id": "dCsGOJLGEypF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# based on VQA Evaluation Code\n",
        "# --------------------------------------------------------\n",
        "\n",
        "contractions = {\n",
        "    \"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\":\n",
        "    \"could've\", \"couldnt\": \"couldn't\", \"couldn'tve\": \"couldn't've\",\n",
        "    \"couldnt've\": \"couldn't've\", \"didnt\": \"didn't\", \"doesnt\":\n",
        "    \"doesn't\", \"dont\": \"don't\", \"hadnt\": \"hadn't\", \"hadnt've\":\n",
        "    \"hadn't've\", \"hadn'tve\": \"hadn't've\", \"hasnt\": \"hasn't\", \"havent\":\n",
        "    \"haven't\", \"hed\": \"he'd\", \"hed've\": \"he'd've\", \"he'dve\":\n",
        "    \"he'd've\", \"hes\": \"he's\", \"howd\": \"how'd\", \"howll\": \"how'll\",\n",
        "    \"hows\": \"how's\", \"Id've\": \"I'd've\", \"I'dve\": \"I'd've\", \"Im\":\n",
        "    \"I'm\", \"Ive\": \"I've\", \"isnt\": \"isn't\", \"itd\": \"it'd\", \"itd've\":\n",
        "    \"it'd've\", \"it'dve\": \"it'd've\", \"itll\": \"it'll\", \"let's\": \"let's\",\n",
        "    \"maam\": \"ma'am\", \"mightnt\": \"mightn't\", \"mightnt've\":\n",
        "    \"mightn't've\", \"mightn'tve\": \"mightn't've\", \"mightve\": \"might've\",\n",
        "    \"mustnt\": \"mustn't\", \"mustve\": \"must've\", \"neednt\": \"needn't\",\n",
        "    \"notve\": \"not've\", \"oclock\": \"o'clock\", \"oughtnt\": \"oughtn't\",\n",
        "    \"ow's'at\": \"'ow's'at\", \"'ows'at\": \"'ow's'at\", \"'ow'sat\":\n",
        "    \"'ow's'at\", \"shant\": \"shan't\", \"shed've\": \"she'd've\", \"she'dve\":\n",
        "    \"she'd've\", \"she's\": \"she's\", \"shouldve\": \"should've\", \"shouldnt\":\n",
        "    \"shouldn't\", \"shouldnt've\": \"shouldn't've\", \"shouldn'tve\":\n",
        "    \"shouldn't've\", \"somebody'd\": \"somebodyd\", \"somebodyd've\":\n",
        "    \"somebody'd've\", \"somebody'dve\": \"somebody'd've\", \"somebodyll\":\n",
        "    \"somebody'll\", \"somebodys\": \"somebody's\", \"someoned\": \"someone'd\",\n",
        "    \"someoned've\": \"someone'd've\", \"someone'dve\": \"someone'd've\",\n",
        "    \"someonell\": \"someone'll\", \"someones\": \"someone's\", \"somethingd\":\n",
        "    \"something'd\", \"somethingd've\": \"something'd've\", \"something'dve\":\n",
        "    \"something'd've\", \"somethingll\": \"something'll\", \"thats\":\n",
        "    \"that's\", \"thered\": \"there'd\", \"thered've\": \"there'd've\",\n",
        "    \"there'dve\": \"there'd've\", \"therere\": \"there're\", \"theres\":\n",
        "    \"there's\", \"theyd\": \"they'd\", \"theyd've\": \"they'd've\", \"they'dve\":\n",
        "    \"they'd've\", \"theyll\": \"they'll\", \"theyre\": \"they're\", \"theyve\":\n",
        "    \"they've\", \"twas\": \"'twas\", \"wasnt\": \"wasn't\", \"wed've\":\n",
        "    \"we'd've\", \"we'dve\": \"we'd've\", \"weve\": \"we've\", \"werent\":\n",
        "    \"weren't\", \"whatll\": \"what'll\", \"whatre\": \"what're\", \"whats\":\n",
        "    \"what's\", \"whatve\": \"what've\", \"whens\": \"when's\", \"whered\":\n",
        "    \"where'd\", \"wheres\": \"where's\", \"whereve\": \"where've\", \"whod\":\n",
        "    \"who'd\", \"whod've\": \"who'd've\", \"who'dve\": \"who'd've\", \"wholl\":\n",
        "    \"who'll\", \"whos\": \"who's\", \"whove\": \"who've\", \"whyll\": \"why'll\",\n",
        "    \"whyre\": \"why're\", \"whys\": \"why's\", \"wont\": \"won't\", \"wouldve\":\n",
        "    \"would've\", \"wouldnt\": \"wouldn't\", \"wouldnt've\": \"wouldn't've\",\n",
        "    \"wouldn'tve\": \"wouldn't've\", \"yall\": \"y'all\", \"yall'll\":\n",
        "    \"y'all'll\", \"y'allll\": \"y'all'll\", \"yall'd've\": \"y'all'd've\",\n",
        "    \"y'alld've\": \"y'all'd've\", \"y'all'dve\": \"y'all'd've\", \"youd\":\n",
        "    \"you'd\", \"youd've\": \"you'd've\", \"you'dve\": \"you'd've\", \"youll\":\n",
        "    \"you'll\", \"youre\": \"you're\", \"youve\": \"you've\"\n",
        "}\n",
        "\n",
        "manual_map = { 'none': '0',\n",
        "              'zero': '0',\n",
        "              'one': '1',\n",
        "              'two': '2',\n",
        "              'three': '3',\n",
        "              'four': '4',\n",
        "              'five': '5',\n",
        "              'six': '6',\n",
        "              'seven': '7',\n",
        "              'eight': '8',\n",
        "               'nine': '9',\n",
        "              'ten': '10'}\n",
        "articles = ['a', 'an', 'the']\n",
        "period_strip = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
        "comma_strip = re.compile(\"(\\d)(\\,)(\\d)\")\n",
        "punct = [';', r\"/\", '[', ']', '\"', '{', '}',\n",
        "                '(', ')', '=', '+', '\\\\', '_', '-',\n",
        "                '>', '<', '@', '`', ',', '?', '!']\n",
        "\n",
        "def process_punctuation(inText):\n",
        "    outText = inText\n",
        "    for p in punct:\n",
        "        if (p + ' ' in inText or ' ' + p in inText) \\\n",
        "           or (re.search(comma_strip, inText) != None):\n",
        "            outText = outText.replace(p, '')\n",
        "        else:\n",
        "            outText = outText.replace(p, ' ')\n",
        "    outText = period_strip.sub(\"\", outText, re.UNICODE)\n",
        "    return outText\n",
        "\n",
        "\n",
        "def process_digit_article(inText):\n",
        "    outText = []\n",
        "    tempText = inText.lower().split()\n",
        "    for word in tempText:\n",
        "        word = manual_map.setdefault(word, word)\n",
        "        if word not in articles:\n",
        "            outText.append(word)\n",
        "        else:\n",
        "            pass\n",
        "    for wordId, word in enumerate(outText):\n",
        "        if word in contractions:\n",
        "            outText[wordId] = contractions[word]\n",
        "    outText = ' '.join(outText)\n",
        "    return outText\n",
        "\n",
        "\n",
        "def prep_ans(answer):\n",
        "    answer = process_digit_article(process_punctuation(answer))\n",
        "    answer = answer.replace(',', '')\n",
        "    return answer\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# --------------------------------------------------------\n",
        "\n",
        "\n",
        "def shuffle_list(ans_list):\n",
        "    random.shuffle(ans_list)\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# ---- Initialization Utils ----\n",
        "# ------------------------------\n",
        "\n",
        "def img_feat_path_load(path_list):\n",
        "    iid_to_path = {}\n",
        "\n",
        "    for ix, path in enumerate(path_list):\n",
        "        iid = str(int(path.split('/')[-1].split('_')[-1].split('.')[0]))\n",
        "        iid_to_path[iid] = path\n",
        "\n",
        "    return iid_to_path\n",
        "\n",
        "\n",
        "def img_feat_load(path_list):\n",
        "    iid_to_feat = {}\n",
        "\n",
        "    for ix, path in enumerate(path_list):\n",
        "        iid = str(int(path.split('/')[-1].split('_')[-1].split('.')[0]))\n",
        "        img_feat = np.load(path)\n",
        "        img_feat_x = img_feat['x'].transpose((1, 0))\n",
        "        iid_to_feat[iid] = img_feat_x\n",
        "        print('\\rPre-Loading: [{} | {}] '.format(ix, path_list.__len__()), end='          ')\n",
        "\n",
        "    return iid_to_feat\n",
        "\n",
        "\n",
        "def ques_load(ques_list):\n",
        "    qid_to_ques = {}\n",
        "\n",
        "    for ques in ques_list:\n",
        "        qid = str(ques['question_id'])\n",
        "        qid_to_ques[qid] = ques\n",
        "\n",
        "    return qid_to_ques\n",
        "\n",
        "\n",
        "def tokenize(stat_ques_list, use_glove):\n",
        "    token_to_ix = {\n",
        "        'PAD': 0,\n",
        "        'UNK': 1,\n",
        "    }\n",
        "\n",
        "    spacy_tool = None\n",
        "    pretrained_emb = []\n",
        "    if use_glove:\n",
        "        spacy_tool = en_vectors_web_lg.load()\n",
        "        pretrained_emb.append(spacy_tool('PAD').vector)\n",
        "        pretrained_emb.append(spacy_tool('UNK').vector)\n",
        "\n",
        "    for ques in stat_ques_list:\n",
        "        words = re.sub(\n",
        "            r\"([.,'!?\\\"()*#:;])\",\n",
        "            '',\n",
        "            ques['question'].lower()\n",
        "        ).replace('-', ' ').replace('/', ' ').split()\n",
        "\n",
        "        for word in words:\n",
        "            if word not in token_to_ix:\n",
        "                token_to_ix[word] = len(token_to_ix)\n",
        "                if use_glove:\n",
        "                    pretrained_emb.append(spacy_tool(word).vector)\n",
        "\n",
        "    pretrained_emb = np.array(pretrained_emb)\n",
        "\n",
        "    return token_to_ix, pretrained_emb\n",
        "\n",
        "\n",
        "# def ans_stat(stat_ans_list, ans_freq):\n",
        "#     ans_to_ix = {}\n",
        "#     ix_to_ans = {}\n",
        "#     ans_freq_dict = {}\n",
        "#\n",
        "#     for ans in stat_ans_list:\n",
        "#         ans_proc = prep_ans(ans['multiple_choice_answer'])\n",
        "#         if ans_proc not in ans_freq_dict:\n",
        "#             ans_freq_dict[ans_proc] = 1\n",
        "#         else:\n",
        "#             ans_freq_dict[ans_proc] += 1\n",
        "#\n",
        "#     ans_freq_filter = ans_freq_dict.copy()\n",
        "#     for ans in ans_freq_dict:\n",
        "#         if ans_freq_dict[ans] <= ans_freq:\n",
        "#             ans_freq_filter.pop(ans)\n",
        "#\n",
        "#     for ans in ans_freq_filter:\n",
        "#         ix_to_ans[ans_to_ix.__len__()] = ans\n",
        "#         ans_to_ix[ans] = ans_to_ix.__len__()\n",
        "#\n",
        "#     return ans_to_ix, ix_to_ans\n",
        "\n",
        "\n",
        "def ans_stat(json_file):\n",
        "    ans_to_ix, ix_to_ans = json.load(open(json_file, 'r'))\n",
        "\n",
        "    return ans_to_ix, ix_to_ans\n",
        "\n",
        "\n",
        "# ------------------------------------\n",
        "# ---- Real-Time Processing Utils ----\n",
        "# ------------------------------------\n",
        "\n",
        "def proc_img_feat(img_feat, img_feat_pad_size):\n",
        "    if img_feat.shape[0] > img_feat_pad_size:\n",
        "        img_feat = img_feat[:img_feat_pad_size]\n",
        "\n",
        "    img_feat = np.pad(\n",
        "        img_feat,\n",
        "        ((0, img_feat_pad_size - img_feat.shape[0]), (0, 0)),\n",
        "        mode='constant',\n",
        "        constant_values=0\n",
        "    )\n",
        "\n",
        "    return img_feat\n",
        "\n",
        "\n",
        "def proc_ques(ques, token_to_ix, max_token):\n",
        "    ques_ix = np.zeros(max_token, np.int64)\n",
        "\n",
        "    words = re.sub(\n",
        "        r\"([.,'!?\\\"()*#:;])\",\n",
        "        '',\n",
        "        ques['question'].lower()\n",
        "    ).replace('-', ' ').replace('/', ' ').split()\n",
        "\n",
        "    for ix, word in enumerate(words):\n",
        "        if word in token_to_ix:\n",
        "            ques_ix[ix] = token_to_ix[word]\n",
        "        else:\n",
        "            ques_ix[ix] = token_to_ix['UNK']\n",
        "\n",
        "        if ix + 1 == max_token:\n",
        "            break\n",
        "\n",
        "    return ques_ix\n",
        "\n",
        "\n",
        "def get_score(occur):\n",
        "    if occur == 0:\n",
        "        return .0\n",
        "    elif occur == 1:\n",
        "        return .3\n",
        "    elif occur == 2:\n",
        "        return .6\n",
        "    elif occur == 3:\n",
        "        return .9\n",
        "    else:\n",
        "        return 1.\n",
        "\n",
        "\n",
        "def proc_ans(ans, ans_to_ix):\n",
        "    ans_score = np.zeros(ans_to_ix.__len__(), np.float32)\n",
        "    ans_prob_dict = {}\n",
        "\n",
        "    for ans_ in ans['answers']:\n",
        "        ans_proc = prep_ans(ans_['answer'])\n",
        "        if ans_proc not in ans_prob_dict:\n",
        "            ans_prob_dict[ans_proc] = 1\n",
        "        else:\n",
        "            ans_prob_dict[ans_proc] += 1\n",
        "\n",
        "    for ans_ in ans_prob_dict:\n",
        "        if ans_ in ans_to_ix:\n",
        "            ans_score[ans_to_ix[ans_]] = get_score(ans_prob_dict[ans_])\n",
        "\n",
        "    return ans_score\n",
        "\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# --------------------------------------------------------\n",
        "\n",
        "\n",
        "class DataSet(Data.Dataset):\n",
        "    def __init__(self, __C):\n",
        "        self.__C = __C\n",
        "\n",
        "\n",
        "        # --------------------------\n",
        "        # ---- Raw data loading ----\n",
        "        # --------------------------\n",
        "\n",
        "        # Loading all image paths\n",
        "        # if self.__C.PRELOAD:\n",
        "        self.img_feat_path_list = []\n",
        "        split_list = __C.SPLIT[__C.RUN_MODE].split('+')\n",
        "        for split in split_list:\n",
        "            if split in ['train', 'val', 'test']:\n",
        "                self.img_feat_path_list += glob.glob(__C.IMG_FEAT_PATH[split] + '*.npz')\n",
        "\n",
        "        # if __C.EVAL_EVERY_EPOCH and __C.RUN_MODE in ['train']:\n",
        "        #     self.img_feat_path_list += glob.glob(__C.IMG_FEAT_PATH['val'] + '*.npz')\n",
        "\n",
        "        # else:\n",
        "        #     self.img_feat_path_list = \\\n",
        "        #         glob.glob(__C.IMG_FEAT_PATH['train'] + '*.npz') + \\\n",
        "        #         glob.glob(__C.IMG_FEAT_PATH['val'] + '*.npz') + \\\n",
        "        #         glob.glob(__C.IMG_FEAT_PATH['test'] + '*.npz')\n",
        "\n",
        "        # Loading question word list\n",
        "        self.stat_ques_list = \\\n",
        "            json.load(open(__C.QUESTION_PATH['train'], 'r'))['questions'] + \\\n",
        "            json.load(open(__C.QUESTION_PATH['val'], 'r'))['questions'] + \\\n",
        "            json.load(open(__C.QUESTION_PATH['test'], 'r'))['questions'] + \\\n",
        "            json.load(open(__C.QUESTION_PATH['vg'], 'r'))['questions']\n",
        "\n",
        "        # Loading answer word list\n",
        "        # self.stat_ans_list = \\\n",
        "        #     json.load(open(__C.ANSWER_PATH['train'], 'r'))['annotations'] + \\\n",
        "        #     json.load(open(__C.ANSWER_PATH['val'], 'r'))['annotations']\n",
        "\n",
        "        # Loading question and answer list\n",
        "        self.ques_list = []\n",
        "        self.ans_list = []\n",
        "\n",
        "        split_list = __C.SPLIT[__C.RUN_MODE].split('+')\n",
        "        for split in split_list:\n",
        "            self.ques_list += json.load(open(__C.QUESTION_PATH[split], 'r'))['questions']\n",
        "            if __C.RUN_MODE in ['train']:\n",
        "                self.ans_list += json.load(open(__C.ANSWER_PATH[split], 'r'))['annotations']\n",
        "\n",
        "        # Define run data size\n",
        "        if __C.RUN_MODE in ['train']:\n",
        "            self.data_size = self.ans_list.__len__()\n",
        "        else:\n",
        "            self.data_size = self.ques_list.__len__()\n",
        "\n",
        "        print('== Dataset size:', self.data_size)\n",
        "\n",
        "\n",
        "        # ------------------------\n",
        "        # ---- Data statistic ----\n",
        "        # ------------------------\n",
        "\n",
        "        # {image id} -> {image feature absolutely path}\n",
        "        if self.__C.PRELOAD:\n",
        "            print('==== Pre-Loading features ...')\n",
        "            time_start = time.time()\n",
        "            self.iid_to_img_feat = img_feat_load(self.img_feat_path_list)\n",
        "            time_end = time.time()\n",
        "            print('==== Finished in {}s'.format(int(time_end-time_start)))\n",
        "        else:\n",
        "            self.iid_to_img_feat_path = img_feat_path_load(self.img_feat_path_list)\n",
        "\n",
        "        # {question id} -> {question}\n",
        "        self.qid_to_ques = ques_load(self.ques_list)\n",
        "\n",
        "        # Tokenize\n",
        "        self.token_to_ix, self.pretrained_emb = tokenize(self.stat_ques_list, __C.USE_GLOVE)\n",
        "        self.token_size = self.token_to_ix.__len__()\n",
        "        print('== Question token vocab size:', self.token_size)\n",
        "\n",
        "        # Answers statistic\n",
        "        # Make answer dict during training does not guarantee\n",
        "        # the same order of {ans_to_ix}, so we published our\n",
        "        # answer dict to ensure that our pre-trained model\n",
        "        # can be adapted on each machine.\n",
        "\n",
        "        # Thanks to Licheng Yu (https://github.com/lichengunc)\n",
        "        # for finding this bug and providing the solutions.\n",
        "\n",
        "        # self.ans_to_ix, self.ix_to_ans = ans_stat(self.stat_ans_list, __C.ANS_FREQ)\n",
        "        self.ans_to_ix, self.ix_to_ans = ans_stat('../input/vqa-coatt/answer_dict.json')\n",
        "        self.ans_size = self.ans_to_ix.__len__()\n",
        "        print('== Answer vocab size (occurr more than {} times):'.format(8), self.ans_size)\n",
        "        print('Finished!')\n",
        "        print('')\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # For code safety\n",
        "        img_feat_iter = np.zeros(1)\n",
        "        ques_ix_iter = np.zeros(1)\n",
        "        ans_iter = np.zeros(1)\n",
        "\n",
        "        # Process ['train'] and ['val', 'test'] respectively\n",
        "        if self.__C.RUN_MODE in ['train']:\n",
        "            # Load the run data from list\n",
        "            ans = self.ans_list[idx]\n",
        "            ques = self.qid_to_ques[str(ans['question_id'])]\n",
        "\n",
        "            # Process image feature from (.npz) file\n",
        "            if self.__C.PRELOAD:\n",
        "                img_feat_x = self.iid_to_img_feat[str(ans['image_id'])]\n",
        "            else:\n",
        "                img_feat = np.load(self.iid_to_img_feat_path[str(ans['image_id'])])\n",
        "                img_feat_x = img_feat['x'].transpose((1, 0))\n",
        "            img_feat_iter = proc_img_feat(img_feat_x, self.__C.IMG_FEAT_PAD_SIZE)\n",
        "\n",
        "            # Process question\n",
        "            ques_ix_iter = proc_ques(ques, self.token_to_ix, self.__C.MAX_TOKEN)\n",
        "\n",
        "            # Process answer\n",
        "            ans_iter = proc_ans(ans, self.ans_to_ix)\n",
        "\n",
        "        else:\n",
        "            # Load the run data from list\n",
        "            ques = self.ques_list[idx]\n",
        "\n",
        "            # # Process image feature from (.npz) file\n",
        "            # img_feat = np.load(self.iid_to_img_feat_path[str(ques['image_id'])])\n",
        "            # img_feat_x = img_feat['x'].transpose((1, 0))\n",
        "            # Process image feature from (.npz) file\n",
        "            if self.__C.PRELOAD:\n",
        "                img_feat_x = self.iid_to_img_feat[str(ques['image_id'])]\n",
        "            else:\n",
        "                img_feat = np.load(self.iid_to_img_feat_path[str(ques['image_id'])])\n",
        "                img_feat_x = img_feat['x'].transpose((1, 0))\n",
        "            img_feat_iter = proc_img_feat(img_feat_x, self.__C.IMG_FEAT_PAD_SIZE)\n",
        "\n",
        "            # Process question\n",
        "            ques_ix_iter = proc_ques(ques, self.token_to_ix, self.__C.MAX_TOKEN)\n",
        "\n",
        "\n",
        "        return torch.from_numpy(img_feat_iter), \\\n",
        "               torch.from_numpy(ques_ix_iter), \\\n",
        "               torch.from_numpy(ans_iter)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-08T23:55:11.243083Z",
          "iopub.execute_input": "2022-07-08T23:55:11.243314Z",
          "iopub.status.idle": "2022-07-08T23:55:11.305918Z",
          "shell.execute_reply.started": "2022-07-08T23:55:11.243278Z",
          "shell.execute_reply": "2022-07-08T23:55:11.30525Z"
        },
        "trusted": true,
        "id": "mjKpDGMhEypO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --------------------------------------------------------\n",
        "# # mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# # Licensed under The MIT License [see LICENSE for details]\n",
        "# # Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# # --------------------------------------------------------\n",
        "\n",
        "# import sys\n",
        "# sys.path.append('../')\n",
        "# from core.data.ans_punct import prep_ans\n",
        "# import json\n",
        "\n",
        "# DATASET_PATH = '../datasets/vqa/'\n",
        "\n",
        "# ANSWER_PATH = {\n",
        "#     'train': DATASET_PATH + 'v2_mscoco_train2014_annotations.json',\n",
        "#     'val': DATASET_PATH + 'v2_mscoco_val2014_annotations.json',\n",
        "#     'vg': DATASET_PATH + 'VG_annotations.json',\n",
        "# }\n",
        "\n",
        "# # Loading answer word list\n",
        "# stat_ans_list = \\\n",
        "#     json.load(open(ANSWER_PATH['train'], 'r'))['annotations'] + \\\n",
        "#     json.load(open(ANSWER_PATH['val'], 'r'))['annotations']\n",
        "\n",
        "\n",
        "# def ans_stat(stat_ans_list):\n",
        "#     ans_to_ix = {}\n",
        "#     ix_to_ans = {}\n",
        "#     ans_freq_dict = {}\n",
        "\n",
        "#     for ans in stat_ans_list:\n",
        "#         ans_proc = prep_ans(ans['multiple_choice_answer'])\n",
        "#         if ans_proc not in ans_freq_dict:\n",
        "#             ans_freq_dict[ans_proc] = 1\n",
        "#         else:\n",
        "#             ans_freq_dict[ans_proc] += 1\n",
        "\n",
        "#     ans_freq_filter = ans_freq_dict.copy()\n",
        "#     for ans in ans_freq_dict:\n",
        "#         if ans_freq_dict[ans] <= 8:\n",
        "#             ans_freq_filter.pop(ans)\n",
        "\n",
        "#     for ans in ans_freq_filter:\n",
        "#         ix_to_ans[ans_to_ix.__len__()] = ans\n",
        "#         ans_to_ix[ans] = ans_to_ix.__len__()\n",
        "\n",
        "#     return ans_to_ix, ix_to_ans\n",
        "\n",
        "# ans_to_ix, ix_to_ans = ans_stat(stat_ans_list)\n",
        "# # print(ans_to_ix.__len__())\n",
        "# json.dump([ans_to_ix, ix_to_ans], open('../core/data/answer_dict.json', 'w'))\n",
        "\n",
        "# __author__ = 'aagrawal'\n",
        "# __version__ = '0.9'\n",
        "\n",
        "# # Interface for accessing the VQA dataset.\n",
        "\n",
        "# # This code is based on the code written by Tsung-Yi Lin for MSCOCO Python API available at the following link: \n",
        "# # (https://github.com/pdollar/coco/blob/master/PythonAPI/pycocotools/coco.py).\n",
        "\n",
        "# # The following functions are defined:\n",
        "# #  VQA        - VQA class that loads VQA annotation file and prepares data structures.\n",
        "# #  getQuesIds - Get question ids that satisfy given filter conditions.\n",
        "# #  getImgIds  - Get image ids that satisfy given filter conditions.\n",
        "# #  loadQA     - Load questions and answers with the specified question ids.\n",
        "# #  showQA     - Display the specified questions and answers.\n",
        "# #  loadRes    - Load result file and create result object.\n",
        "\n",
        "# # Help on each function can be accessed by: \"help(COCO.function)\"\n",
        "\n",
        "# import json\n",
        "# import datetime\n",
        "# import copy\n",
        "\n",
        "\n",
        "# class VQA:\n",
        "# \tdef __init__(self, annotation_file=None, question_file=None):\n",
        "# \t\t\"\"\"\n",
        "#        \tConstructor of VQA helper class for reading and visualizing questions and answers.\n",
        "#         :param annotation_file (str): location of VQA annotation file\n",
        "#         :return:\n",
        "# \t\t\"\"\"\n",
        "# \t\t# load dataset\n",
        "# \t\tself.dataset = {}\n",
        "# \t\tself.questions = {}\n",
        "# \t\tself.qa = {}\n",
        "# \t\tself.qqa = {}\n",
        "# \t\tself.imgToQA = {}\n",
        "# \t\tif not annotation_file == None and not question_file == None:\n",
        "# \t\t\tprint('loading VQA annotations and questions into memory...')\n",
        "# \t\t\ttime_t = datetime.datetime.utcnow()\n",
        "# \t\t\tdataset = json.load(open(annotation_file, 'r'))\n",
        "# \t\t\tquestions = json.load(open(question_file, 'r'))\n",
        "# \t\t\tprint(datetime.datetime.utcnow() - time_t)\n",
        "# \t\t\tself.dataset = dataset\n",
        "# \t\t\tself.questions = questions\n",
        "# \t\t\tself.createIndex()\n",
        "\n",
        "# \tdef createIndex(self):\n",
        "# \t\t# create index\n",
        "# \t\tprint('creating index...')\n",
        "# \t\timgToQA = {ann['image_id']: [] for ann in self.dataset['annotations']}\n",
        "# \t\tqa = {ann['question_id']: [] for ann in self.dataset['annotations']}\n",
        "# \t\tqqa = {ann['question_id']: [] for ann in self.dataset['annotations']}\n",
        "# \t\tfor ann in self.dataset['annotations']:\n",
        "# \t\t\timgToQA[ann['image_id']] += [ann]\n",
        "# \t\t\tqa[ann['question_id']] = ann\n",
        "# \t\tfor ques in self.questions['questions']:\n",
        "# \t\t\tqqa[ques['question_id']] = ques\n",
        "# \t\tprint('index created!')\n",
        "\n",
        "# \t\t# create class members\n",
        "# \t\tself.qa = qa\n",
        "# \t\tself.qqa = qqa\n",
        "# \t\tself.imgToQA = imgToQA\n",
        "\n",
        "# \tdef info(self):\n",
        "# \t\t\"\"\"\n",
        "# \t\tPrint information about the VQA annotation file.\n",
        "# \t\t:return:\n",
        "# \t\t\"\"\"\n",
        "# \t\tfor key, value in self.dataset['info'].items():\n",
        "# \t\t\tprint('%s: %s' % (key, value))\n",
        "\n",
        "# \tdef getQuesIds(self, imgIds=[], quesTypes=[], ansTypes=[]):\n",
        "# \t\t\"\"\"\n",
        "# \t\tGet question ids that satisfy given filter conditions. default skips that filter\n",
        "# \t\t:param \timgIds    (int array)   : get question ids for given imgs\n",
        "# \t\t\t\tquesTypes (str array)   : get question ids for given question types\n",
        "# \t\t\t\tansTypes  (str array)   : get question ids for given answer types\n",
        "# \t\t:return:    ids   (int array)   : integer array of question ids\n",
        "# \t\t\"\"\"\n",
        "# \t\timgIds = imgIds if type(imgIds) == list else [imgIds]\n",
        "# \t\tquesTypes = quesTypes if type(quesTypes) == list else [quesTypes]\n",
        "# \t\tansTypes = ansTypes if type(ansTypes) == list else [ansTypes]\n",
        "\n",
        "# \t\tif len(imgIds) == len(quesTypes) == len(ansTypes) == 0:\n",
        "# \t\t\tanns = self.dataset['annotations']\n",
        "# \t\telse:\n",
        "# \t\t\tif not len(imgIds) == 0:\n",
        "# \t\t\t\tanns = sum([self.imgToQA[imgId] for imgId in imgIds if imgId in self.imgToQA], [])\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tanns = self.dataset['annotations']\n",
        "# \t\t\tanns = anns if len(quesTypes) == 0 else [ann for ann in anns if ann['question_type'] in quesTypes]\n",
        "# \t\t\tanns = anns if len(ansTypes) == 0 else [ann for ann in anns if ann['answer_type'] in ansTypes]\n",
        "# \t\tids = [ann['question_id'] for ann in anns]\n",
        "# \t\treturn ids\n",
        "\n",
        "# \tdef getImgIds(self, quesIds=[], quesTypes=[], ansTypes=[]):\n",
        "# \t\t\"\"\"\n",
        "# \t\tGet image ids that satisfy given filter conditions. default skips that filter\n",
        "# \t\t:param quesIds   (int array)   : get image ids for given question ids\n",
        "#                quesTypes (str array)   : get image ids for given question types\n",
        "#                ansTypes  (str array)   : get image ids for given answer types\n",
        "# \t\t:return: ids     (int array)   : integer array of image ids\n",
        "# \t\t\"\"\"\n",
        "# \t\tquesIds = quesIds if type(quesIds) == list else [quesIds]\n",
        "# \t\tquesTypes = quesTypes if type(quesTypes) == list else [quesTypes]\n",
        "# \t\tansTypes = ansTypes if type(ansTypes) == list else [ansTypes]\n",
        "\n",
        "# \t\tif len(quesIds) == len(quesTypes) == len(ansTypes) == 0:\n",
        "# \t\t\tanns = self.dataset['annotations']\n",
        "# \t\telse:\n",
        "# \t\t\tif not len(quesIds) == 0:\n",
        "# \t\t\t\tanns = sum([self.qa[quesId] for quesId in quesIds if quesId in self.qa], [])\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tanns = self.dataset['annotations']\n",
        "# \t\t\tanns = anns if len(quesTypes) == 0 else [ann for ann in anns if ann['question_type'] in quesTypes]\n",
        "# \t\t\tanns = anns if len(ansTypes) == 0 else [ann for ann in anns if ann['answer_type'] in ansTypes]\n",
        "# \t\tids = [ann['image_id'] for ann in anns]\n",
        "# \t\treturn ids\n",
        "\n",
        "# \tdef loadQA(self, ids=[]):\n",
        "# \t\t\"\"\"\n",
        "# \t\tLoad questions and answers with the specified question ids.\n",
        "# \t\t:param ids (int array)       : integer ids specifying question ids\n",
        "# \t\t:return: qa (object array)   : loaded qa objects\n",
        "# \t\t\"\"\"\n",
        "# \t\tif type(ids) == list:\n",
        "# \t\t\treturn [self.qa[id] for id in ids]\n",
        "# \t\telif type(ids) == int:\n",
        "# \t\t\treturn [self.qa[ids]]\n",
        "\n",
        "# \tdef showQA(self, anns):\n",
        "# \t\t\"\"\"\n",
        "# \t\tDisplay the specified annotations.\n",
        "# \t\t:param anns (array of object): annotations to display\n",
        "# \t\t:return: None\n",
        "# \t\t\"\"\"\n",
        "# \t\tif len(anns) == 0:\n",
        "# \t\t\treturn 0\n",
        "# \t\tfor ann in anns:\n",
        "# \t\t\tquesId = ann['question_id']\n",
        "# \t\t\tprint(\"Question: %s\" % (self.qqa[quesId]['question']))\n",
        "# \t\t\tfor ans in ann['answers']:\n",
        "# \t\t\t\tprint(\"Answer %d: %s\" % (ans['answer_id'], ans['answer']))\n",
        "\n",
        "# \tdef loadRes(self, resFile, quesFile):\n",
        "# \t\t\"\"\"\n",
        "# \t\tLoad result file and return a result object.\n",
        "# \t\t:param   resFile (str)     : file name of result file\n",
        "# \t\t:return: res (obj)         : result api object\n",
        "# \t\t\"\"\"\n",
        "# \t\tres = VQA()\n",
        "# \t\tres.questions = json.load(open(quesFile))\n",
        "# \t\tres.dataset['info'] = copy.deepcopy(self.questions['info'])\n",
        "# \t\tres.dataset['task_type'] = copy.deepcopy(self.questions['task_type'])\n",
        "# \t\tres.dataset['data_type'] = copy.deepcopy(self.questions['data_type'])\n",
        "# \t\tres.dataset['data_subtype'] = copy.deepcopy(self.questions['data_subtype'])\n",
        "# \t\tres.dataset['license'] = copy.deepcopy(self.questions['license'])\n",
        "\n",
        "# \t\tprint('Loading and preparing results...     ')\n",
        "# \t\ttime_t = datetime.datetime.utcnow()\n",
        "# \t\tanns = json.load(open(resFile))\n",
        "# \t\tassert type(anns) == list, 'results is not an array of objects'\n",
        "# \t\tannsQuesIds = [ann['question_id'] for ann in anns]\n",
        "# \t\tassert set(annsQuesIds) == set(self.getQuesIds()), \\\n",
        "# \t\t\t'Results do not correspond to current VQA set. Either the results do not have predictions for all question ids in annotation file or there is atleast one question id that does not belong to the question ids in the annotation file.'\n",
        "# \t\tfor ann in anns:\n",
        "# \t\t\tquesId = ann['question_id']\n",
        "# \t\t\tif res.dataset['task_type'] == 'Multiple Choice':\n",
        "# \t\t\t\tassert ann['answer'] in self.qqa[quesId][\n",
        "# \t\t\t\t\t'multiple_choices'], 'predicted answer is not one of the multiple choices'\n",
        "# \t\t\tqaAnn = self.qa[quesId]\n",
        "# \t\t\tann['image_id'] = qaAnn['image_id']\n",
        "# \t\t\tann['question_type'] = qaAnn['question_type']\n",
        "# \t\t\tann['answer_type'] = qaAnn['answer_type']\n",
        "# \t\tprint('DONE (t=%0.2fs)' % ((datetime.datetime.utcnow() - time_t).total_seconds()))\n",
        "\n",
        "# \t\tres.dataset['annotations'] = anns\n",
        "# \t\tres.createIndex()\n",
        "# \t\treturn res\n",
        "\n",
        "# # coding=utf-8\n",
        "\n",
        "# __author__='aagrawal'\n",
        "\n",
        "# # This code is based on the code written by Tsung-Yi Lin for MSCOCO Python API available at the following link: \n",
        "# # (https://github.com/tylin/coco-caption/blob/master/pycocoevalcap/eval.py).\n",
        "# import sys\n",
        "# import re\n",
        "\n",
        "# class VQAEval:\n",
        "# \tdef __init__(self, vqa, vqaRes, n=2):\n",
        "# \t\tself.n \t\t\t  = n\n",
        "# \t\tself.accuracy     = {}\n",
        "# \t\tself.evalQA       = {}\n",
        "# \t\tself.evalQuesType = {}\n",
        "# \t\tself.evalAnsType  = {}\n",
        "# \t\tself.vqa \t\t  = vqa\n",
        "# \t\tself.vqaRes       = vqaRes\n",
        "# \t\tself.params\t\t  = {'question_id': vqa.getQuesIds()}\n",
        "# \t\tself.contractions = {\"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\": \"could've\", \"couldnt\": \"couldn't\",\n",
        "# \t\t\t\t\t\t\t \"couldn'tve\": \"couldn't've\", \"couldnt've\": \"couldn't've\", \"didnt\": \"didn't\", \"doesnt\": \"doesn't\", \"dont\": \"don't\", \"hadnt\": \"hadn't\",\n",
        "# \t\t\t\t\t\t\t \"hadnt've\": \"hadn't've\", \"hadn'tve\": \"hadn't've\", \"hasnt\": \"hasn't\", \"havent\": \"haven't\", \"hed\": \"he'd\", \"hed've\": \"he'd've\",\n",
        "# \t\t\t\t\t\t\t \"he'dve\": \"he'd've\", \"hes\": \"he's\", \"howd\": \"how'd\", \"howll\": \"how'll\", \"hows\": \"how's\", \"Id've\": \"I'd've\", \"I'dve\": \"I'd've\",\n",
        "# \t\t\t\t\t\t\t \"Im\": \"I'm\", \"Ive\": \"I've\", \"isnt\": \"isn't\", \"itd\": \"it'd\", \"itd've\": \"it'd've\", \"it'dve\": \"it'd've\", \"itll\": \"it'll\", \"let's\": \"let's\",\n",
        "# \t\t\t\t\t\t\t \"maam\": \"ma'am\", \"mightnt\": \"mightn't\", \"mightnt've\": \"mightn't've\", \"mightn'tve\": \"mightn't've\", \"mightve\": \"might've\",\n",
        "# \t\t\t\t\t\t\t \"mustnt\": \"mustn't\", \"mustve\": \"must've\", \"neednt\": \"needn't\", \"notve\": \"not've\", \"oclock\": \"o'clock\", \"oughtnt\": \"oughtn't\",\n",
        "# \t\t\t\t\t\t\t \"ow's'at\": \"'ow's'at\", \"'ows'at\": \"'ow's'at\", \"'ow'sat\": \"'ow's'at\", \"shant\": \"shan't\", \"shed've\": \"she'd've\", \"she'dve\": \"she'd've\",\n",
        "# \t\t\t\t\t\t\t \"she's\": \"she's\", \"shouldve\": \"should've\", \"shouldnt\": \"shouldn't\", \"shouldnt've\": \"shouldn't've\", \"shouldn'tve\": \"shouldn't've\",\n",
        "# \t\t\t\t\t\t\t \"somebody'd\": \"somebodyd\", \"somebodyd've\": \"somebody'd've\", \"somebody'dve\": \"somebody'd've\", \"somebodyll\": \"somebody'll\",\n",
        "# \t\t\t\t\t\t\t \"somebodys\": \"somebody's\", \"someoned\": \"someone'd\", \"someoned've\": \"someone'd've\", \"someone'dve\": \"someone'd've\",\n",
        "# \t\t\t\t\t\t\t \"someonell\": \"someone'll\", \"someones\": \"someone's\", \"somethingd\": \"something'd\", \"somethingd've\": \"something'd've\",\n",
        "# \t\t\t\t\t\t\t \"something'dve\": \"something'd've\", \"somethingll\": \"something'll\", \"thats\": \"that's\", \"thered\": \"there'd\", \"thered've\": \"there'd've\",\n",
        "# \t\t\t\t\t\t\t \"there'dve\": \"there'd've\", \"therere\": \"there're\", \"theres\": \"there's\", \"theyd\": \"they'd\", \"theyd've\": \"they'd've\",\n",
        "# \t\t\t\t\t\t\t \"they'dve\": \"they'd've\", \"theyll\": \"they'll\", \"theyre\": \"they're\", \"theyve\": \"they've\", \"twas\": \"'twas\", \"wasnt\": \"wasn't\",\n",
        "# \t\t\t\t\t\t\t \"wed've\": \"we'd've\", \"we'dve\": \"we'd've\", \"weve\": \"we've\", \"werent\": \"weren't\", \"whatll\": \"what'll\", \"whatre\": \"what're\",\n",
        "# \t\t\t\t\t\t\t \"whats\": \"what's\", \"whatve\": \"what've\", \"whens\": \"when's\", \"whered\": \"where'd\", \"wheres\": \"where's\", \"whereve\": \"where've\",\n",
        "# \t\t\t\t\t\t\t \"whod\": \"who'd\", \"whod've\": \"who'd've\", \"who'dve\": \"who'd've\", \"wholl\": \"who'll\", \"whos\": \"who's\", \"whove\": \"who've\", \"whyll\": \"why'll\",\n",
        "# \t\t\t\t\t\t\t \"whyre\": \"why're\", \"whys\": \"why's\", \"wont\": \"won't\", \"wouldve\": \"would've\", \"wouldnt\": \"wouldn't\", \"wouldnt've\": \"wouldn't've\",\n",
        "# \t\t\t\t\t\t\t \"wouldn'tve\": \"wouldn't've\", \"yall\": \"y'all\", \"yall'll\": \"y'all'll\", \"y'allll\": \"y'all'll\", \"yall'd've\": \"y'all'd've\",\n",
        "# \t\t\t\t\t\t\t \"y'alld've\": \"y'all'd've\", \"y'all'dve\": \"y'all'd've\", \"youd\": \"you'd\", \"youd've\": \"you'd've\", \"you'dve\": \"you'd've\",\n",
        "# \t\t\t\t\t\t\t \"youll\": \"you'll\", \"youre\": \"you're\", \"youve\": \"you've\"}\n",
        "# \t\tself.manualMap    = { 'none': '0',\n",
        "# \t\t\t\t\t\t\t  'zero': '0',\n",
        "# \t\t\t\t\t\t\t  'one': '1',\n",
        "# \t\t\t\t\t\t\t  'two': '2',\n",
        "# \t\t\t\t\t\t\t  'three': '3',\n",
        "# \t\t\t\t\t\t\t  'four': '4',\n",
        "# \t\t\t\t\t\t\t  'five': '5',\n",
        "# \t\t\t\t\t\t\t  'six': '6',\n",
        "# \t\t\t\t\t\t\t  'seven': '7',\n",
        "# \t\t\t\t\t\t\t  'eight': '8',\n",
        "# \t\t\t\t\t\t\t  'nine': '9',\n",
        "# \t\t\t\t\t\t\t  'ten': '10'\n",
        "# \t\t\t\t\t\t\t}\n",
        "# \t\tself.articles     = ['a',\n",
        "# \t\t\t\t\t\t\t 'an',\n",
        "# \t\t\t\t\t\t\t 'the'\n",
        "# \t\t\t\t\t\t\t]\n",
        " \n",
        "\n",
        "# \t\tself.periodStrip  = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
        "# \t\tself.commaStrip   = re.compile(\"(\\d)(,)(\\d)\")\n",
        "# \t\tself.punct        = [';', r\"/\", '[', ']', '\"', '{', '}',\n",
        "# \t\t\t\t\t\t\t '(', ')', '=', '+', '\\\\', '_', '-',\n",
        "# \t\t\t\t\t\t\t '>', '<', '@', '`', ',', '?', '!']\n",
        "\n",
        "\t\n",
        "# \tdef evaluate(self, quesIds=None):\n",
        "# \t\tif quesIds == None:\n",
        "# \t\t\tquesIds = [quesId for quesId in self.params['question_id']]\n",
        "# \t\tgts = {}\n",
        "# \t\tres = {}\n",
        "# \t\tfor quesId in quesIds:\n",
        "# \t\t\tgts[quesId] = self.vqa.qa[quesId]\n",
        "# \t\t\tres[quesId] = self.vqaRes.qa[quesId]\n",
        "\t\t\n",
        "# \t\t# =================================================\n",
        "# \t\t# Compute accuracy\n",
        "# \t\t# =================================================\n",
        "# \t\taccQA       = []\n",
        "# \t\taccQuesType = {}\n",
        "# \t\taccAnsType  = {}\n",
        "# \t\tprint (\"computing accuracy\")\n",
        "# \t\tstep = 0\n",
        "# \t\tfor quesId in quesIds:\n",
        "# \t\t\tresAns      = res[quesId]['answer']\n",
        "# \t\t\tresAns      = resAns.replace('\\n', ' ')\n",
        "# \t\t\tresAns      = resAns.replace('\\t', ' ')\n",
        "# \t\t\tresAns      = resAns.strip()\n",
        "# \t\t\tresAns      = self.processPunctuation(resAns)\n",
        "# \t\t\tresAns      = self.processDigitArticle(resAns)\n",
        "# \t\t\tgtAcc  = []\n",
        "# \t\t\tgtAnswers = [ans['answer'] for ans in gts[quesId]['answers']]\n",
        "# \t\t\tif len(set(gtAnswers)) > 1: \n",
        "# \t\t\t\tfor ansDic in gts[quesId]['answers']:\n",
        "# \t\t\t\t\tansDic['answer'] = self.processPunctuation(ansDic['answer'])\n",
        "# \t\t\tfor gtAnsDatum in gts[quesId]['answers']:\n",
        "# \t\t\t\totherGTAns = [item for item in gts[quesId]['answers'] if item!=gtAnsDatum]\n",
        "# \t\t\t\tmatchingAns = [item for item in otherGTAns if item['answer']==resAns]\n",
        "# \t\t\t\tacc = min(1, float(len(matchingAns))/3)\n",
        "# \t\t\t\tgtAcc.append(acc)\n",
        "# \t\t\tquesType    = gts[quesId]['question_type']\n",
        "# \t\t\tansType     = gts[quesId]['answer_type']\n",
        "# \t\t\tavgGTAcc = float(sum(gtAcc))/len(gtAcc)\n",
        "# \t\t\taccQA.append(avgGTAcc)\n",
        "# \t\t\tif quesType not in accQuesType:\n",
        "# \t\t\t\taccQuesType[quesType] = []\n",
        "# \t\t\taccQuesType[quesType].append(avgGTAcc)\n",
        "# \t\t\tif ansType not in accAnsType:\n",
        "# \t\t\t\taccAnsType[ansType] = []\n",
        "# \t\t\taccAnsType[ansType].append(avgGTAcc)\n",
        "# \t\t\tself.setEvalQA(quesId, avgGTAcc)\n",
        "# \t\t\tself.setEvalQuesType(quesId, quesType, avgGTAcc)\n",
        "# \t\t\tself.setEvalAnsType(quesId, ansType, avgGTAcc)\n",
        "# \t\t\tif step%100 == 0:\n",
        "# \t\t\t\tself.updateProgress(step/float(len(quesIds)))\n",
        "# \t\t\tstep = step + 1\n",
        "\n",
        "# \t\tself.setAccuracy(accQA, accQuesType, accAnsType)\n",
        "# \t\tprint (\"Done computing accuracy\")\n",
        "\t\n",
        "# \tdef processPunctuation(self, inText):\n",
        "# \t\toutText = inText\n",
        "# \t\tfor p in self.punct:\n",
        "# \t\t\tif (p + ' ' in inText or ' ' + p in inText) or (re.search(self.commaStrip, inText) != None):\n",
        "# \t\t\t\toutText = outText.replace(p, '')\n",
        "# \t\t\telse:\n",
        "# \t\t\t\toutText = outText.replace(p, ' ')\t\n",
        "# \t\toutText = self.periodStrip.sub(\"\",\n",
        "# \t\t\t\t\t\t\t\t\t  outText,\n",
        "# \t\t\t\t\t\t\t\t\t  re.UNICODE)\n",
        "# \t\treturn outText\n",
        "\t\n",
        "# \tdef processDigitArticle(self, inText):\n",
        "# \t\toutText = []\n",
        "# \t\ttempText = inText.lower().split()\n",
        "# \t\tfor word in tempText:\n",
        "# \t\t\tword = self.manualMap.setdefault(word, word)\n",
        "# \t\t\tif word not in self.articles:\n",
        "# \t\t\t\toutText.append(word)\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tpass\n",
        "# \t\tfor wordId, word in enumerate(outText):\n",
        "# \t\t\tif word in self.contractions: \n",
        "# \t\t\t\toutText[wordId] = self.contractions[word]\n",
        "# \t\toutText = ' '.join(outText)\n",
        "# \t\treturn outText\n",
        "\n",
        "# \tdef setAccuracy(self, accQA, accQuesType, accAnsType):\n",
        "# \t\tself.accuracy['overall']         = round(100*float(sum(accQA))/len(accQA), self.n)\n",
        "# \t\tself.accuracy['perQuestionType'] = {quesType: round(100*float(sum(accQuesType[quesType]))/len(accQuesType[quesType]), self.n) for quesType in accQuesType}\n",
        "# \t\tself.accuracy['perAnswerType']   = {ansType:  round(100*float(sum(accAnsType[ansType]))/len(accAnsType[ansType]), self.n) for ansType in accAnsType}\n",
        "\t\t\t\n",
        "# \tdef setEvalQA(self, quesId, acc):\n",
        "# \t\tself.evalQA[quesId] = round(100*acc, self.n)\n",
        "\n",
        "# \tdef setEvalQuesType(self, quesId, quesType, acc):\n",
        "# \t\tif quesType not in self.evalQuesType:\n",
        "# \t\t\tself.evalQuesType[quesType] = {}\n",
        "# \t\tself.evalQuesType[quesType][quesId] = round(100*acc, self.n)\n",
        "\t\n",
        "# \tdef setEvalAnsType(self, quesId, ansType, acc):\n",
        "# \t\tif ansType not in self.evalAnsType:\n",
        "# \t\t\tself.evalAnsType[ansType] = {}\n",
        "# \t\tself.evalAnsType[ansType][quesId] = round(100*acc, self.n)\n",
        "\n",
        "# \tdef updateProgress(self, progress):\n",
        "# \t\tbarLength = 20\n",
        "# \t\tstatus = \"\"\n",
        "# \t\tif isinstance(progress, int):\n",
        "# \t\t\tprogress = float(progress)\n",
        "# \t\tif not isinstance(progress, float):\n",
        "# \t\t\tprogress = 0\n",
        "# \t\t\tstatus = \"error: progress var must be float\\r\\n\"\n",
        "# \t\tif progress < 0:\n",
        "# \t\t\tprogress = 0\n",
        "# \t\t\tstatus = \"Halt...\\r\\n\"\n",
        "# \t\tif progress >= 1:\n",
        "# \t\t\tprogress = 1\n",
        "# \t\t\tstatus = \"Done...\\r\\n\"\n",
        "# \t\tblock = int(round(barLength*progress))\n",
        "# \t\ttext = \"\\rFinshed Percent: [{0}] {1}% {2}\".format( \"#\"*block + \"-\"*(barLength-block), int(progress*100), status)\n",
        "# \t\tsys.stdout.write(text)\n",
        "# \t\tsys.stdout.flush()\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-08T23:55:11.309082Z",
          "iopub.execute_input": "2022-07-08T23:55:11.309308Z",
          "iopub.status.idle": "2022-07-08T23:55:11.329172Z",
          "shell.execute_reply.started": "2022-07-08T23:55:11.309283Z",
          "shell.execute_reply": "2022-07-08T23:55:11.328476Z"
        },
        "trusted": true,
        "id": "a06TfJU0EypT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------\n",
        "# mcan-vqa (Deep Modular Co-Attention Networks)\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Yuhao Cui https://github.com/cuiyuhao1996\n",
        "# --------------------------------------------------------\n",
        "\n",
        "import argparse, yaml\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    '''\n",
        "    Parse input arguments\n",
        "    '''\n",
        "    parser = argparse.ArgumentParser(description='MCAN Args')\n",
        "\n",
        "    parser.add_argument('--RUN', dest='RUN_MODE',\n",
        "                      choices=['train', 'val', 'test'],\n",
        "                      help='{train, val, test}',\n",
        "                      type=str, required=True)\n",
        "\n",
        "    parser.add_argument('--MODEL', dest='MODEL',\n",
        "                      choices=['small', 'large'],\n",
        "                      help='{small, large}',\n",
        "                      default='small', type=str)\n",
        "\n",
        "    parser.add_argument('--SPLIT', dest='TRAIN_SPLIT',\n",
        "                      choices=['train', 'train+val', 'train+val+vg'],\n",
        "                      help=\"set training split, \"\n",
        "                           \"eg.'train', 'train+val+vg'\"\n",
        "                           \"set 'train' can trigger the \"\n",
        "                           \"eval after every epoch\",\n",
        "                      type=str)\n",
        "\n",
        "    parser.add_argument('--EVAL_EE', dest='EVAL_EVERY_EPOCH',\n",
        "                      help='set True to evaluate the '\n",
        "                           'val split when an epoch finished'\n",
        "                           \"(only work when train with \"\n",
        "                           \"'train' split)\",\n",
        "                      type=bool)\n",
        "\n",
        "    parser.add_argument('--SAVE_PRED', dest='TEST_SAVE_PRED',\n",
        "                      help='set True to save the '\n",
        "                           'prediction vectors'\n",
        "                           '(only work in testing)',\n",
        "                      type=bool)\n",
        "\n",
        "    parser.add_argument('--BS', dest='BATCH_SIZE',\n",
        "                      help='batch size during training',\n",
        "                      type=int)\n",
        "\n",
        "    parser.add_argument('--MAX_EPOCH', dest='MAX_EPOCH',\n",
        "                      help='max training epoch',\n",
        "                      type=int)\n",
        "\n",
        "    parser.add_argument('--PRELOAD', dest='PRELOAD',\n",
        "                      help='pre-load the features into memory'\n",
        "                           'to increase the I/O speed',\n",
        "                      type=bool)\n",
        "\n",
        "    parser.add_argument('--GPU', dest='GPU',\n",
        "                      help=\"gpu select, eg.'0, 1, 2'\",\n",
        "                      type=str)\n",
        "\n",
        "    parser.add_argument('--SEED', dest='SEED',\n",
        "                      help='fix random seed',\n",
        "                      type=int)\n",
        "\n",
        "    parser.add_argument('--VERSION', dest='VERSION',\n",
        "                      help='version control',\n",
        "                      type=str)\n",
        "\n",
        "    parser.add_argument('--RESUME', dest='RESUME',\n",
        "                      help='resume training',\n",
        "                      type=bool)\n",
        "\n",
        "    parser.add_argument('--CKPT_V', dest='CKPT_VERSION',\n",
        "                      help='checkpoint version',\n",
        "                      type=str)\n",
        "\n",
        "    parser.add_argument('--CKPT_E', dest='CKPT_EPOCH',\n",
        "                      help='checkpoint epoch',\n",
        "                      type=int)\n",
        "\n",
        "    parser.add_argument('--CKPT_PATH', dest='CKPT_PATH',\n",
        "                      help='load checkpoint path, we '\n",
        "                           'recommend that you use '\n",
        "                           'CKPT_VERSION and CKPT_EPOCH '\n",
        "                           'instead',\n",
        "                      type=str)\n",
        "\n",
        "    parser.add_argument('--ACCU', dest='GRAD_ACCU_STEPS',\n",
        "                      help='reduce gpu memory usage',\n",
        "                      type=int)\n",
        "\n",
        "    parser.add_argument('--NW', dest='NUM_WORKERS',\n",
        "                      help='multithreaded loading',\n",
        "                      type=int)\n",
        "\n",
        "    parser.add_argument('--PINM', dest='PIN_MEM',\n",
        "                      help='use pin memory',\n",
        "                      type=bool)\n",
        "\n",
        "    parser.add_argument('--VERB', dest='VERBOSE',\n",
        "                      help='verbose print',\n",
        "                      type=bool)\n",
        "\n",
        "    parser.add_argument('--DATA_PATH', dest='DATASET_PATH',\n",
        "                      help='vqav2 dataset root path',\n",
        "                      type=str)\n",
        "\n",
        "    parser.add_argument('--FEAT_PATH', dest='FEATURE_PATH',\n",
        "                      help='bottom up features root path',\n",
        "                      type=str)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    __C = Cfgs()\n",
        "\n",
        "#     args = parse_args()\n",
        "#     args_dict = __C.parse_to_dict(args)\n",
        "\n",
        "    args_MODEL = 'small'\n",
        "    args_dict = {'MODEL': 'small', 'RUN_MODE': 'train'}\n",
        "    cfg_file = \"../input/vqa-coatt/{}_model.yml\".format(args_MODEL)\n",
        "    \n",
        "    with open(cfg_file, 'r') as f:\n",
        "        yaml_dict = yaml.load(f,Loader=yaml.SafeLoader)\n",
        "\n",
        "    args_dict = {**yaml_dict, **args_dict}\n",
        "    __C.add_args(args_dict)\n",
        "    __C.proc()\n",
        "\n",
        "    print('Hyper Parameters:')\n",
        "    print(__C)\n",
        "\n",
        "    __C.check_path()\n",
        "\n",
        "    execution = Execution(__C)\n",
        "    execution.run(__C.RUN_MODE)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-08T23:55:11.332468Z",
          "iopub.execute_input": "2022-07-08T23:55:11.33266Z"
        },
        "trusted": true,
        "id": "kSE2zfnlEypa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}